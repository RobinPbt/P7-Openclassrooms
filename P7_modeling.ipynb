{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb37a03",
   "metadata": {},
   "source": [
    "# Table of Contents --> TBU\n",
    "\n",
    "1. [Global parameters](#1-bullet) <br>\n",
    "    <br>\n",
    "    \n",
    "2. [Loading datas](#2-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "3. [Preprocessing](#3-bullet) <br>\n",
    "    I - [Cleaning](#4-bullet) <br>\n",
    "    II - [Split train/test and preprocessing](#5-bullet) <br>\n",
    "    III - [Dimensionality reduction](#6-bullet) <br>\n",
    "    IV - [Creation of folds for cv](#7-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "4. [Baseline model testing](#8-bullet) <br>\n",
    "    I - [Dummy classifiers ](#9-bullet) <br>\n",
    "    II - [Quick testing](#10-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "5. [Cross-validation model testing](#11-bullet) <br>\n",
    "    I - [Linear models](#12-bullet) <br>\n",
    "    II - [KNN](#13-bullet) <br>\n",
    "    III - [SVM](#14-bullet) <br>\n",
    "    IV - [Trees and ensemblist methods](#15-bullet) <br>\n",
    "    V - [Neural networks](#16-bullet) <br>\n",
    "    VI - [Compare](#17-bullet) <br>\n",
    "    <br>\n",
    "    \n",
    "6. [Selected model fine tuning](#18-bullet) <br>\n",
    "    I - [xx](#19-bullet) <br>\n",
    "    II - [xx](#20-bullet) <br>\n",
    "    III - [xx](#21-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "7. [Features importance](#xx-bullet) <br>\n",
    "    I - [xx](#xx-bullet) <br>\n",
    "    II - [xx](#xx-bullet) <br>\n",
    "    III - [xx](#xx-bullet) <br>\n",
    "    <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702077a",
   "metadata": {},
   "source": [
    "# 1. Global parameters <a class=\"anchor\" id=\"1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "40275ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General input\n",
    "random_state = 50 \n",
    "\n",
    "# Cross-validation\n",
    "optimized_metric = 'roc_auc' \n",
    "num_folds = 5\n",
    "stratified = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c16c80",
   "metadata": {},
   "source": [
    "# 2. Loading datas <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a30bce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import timeit\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "# Project specific functions\n",
    "from P7_functions import *\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import manifold, decomposition\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imblearn\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e839d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "74f2bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_csv('./Clean_datas/baseline_data.csv', sep=\",\")\n",
    "data = pd.read_csv('./Clean_datas/clean_data_1.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "32fb710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158397</td>\n",
       "      <td>0.498036</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>247829.081500</td>\n",
       "      <td>888586.065</td>\n",
       "      <td>1.223847</td>\n",
       "      <td>0.227890</td>\n",
       "      <td>0.278903</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>202500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145199</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>292122.185803</td>\n",
       "      <td>2103502.500</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>0.128357</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052803</td>\n",
       "      <td>0.431748</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>121500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0      100002       1         Cash loans           M            N   \n",
       "1           1      100003       0         Cash loans           F            N   \n",
       "2           2      100004       0    Revolving loans           M            Y   \n",
       "3           3      100006       0         Cash loans           F            N   \n",
       "4           4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  ...  \\\n",
       "0               Y             0          202500.0    406597.5  ...   \n",
       "1               N             0          270000.0   1293502.5  ...   \n",
       "2               Y             0           67500.0    135000.0  ...   \n",
       "3               Y             0          135000.0    312682.5  ...   \n",
       "4               Y             0          121500.0    513000.0  ...   \n",
       "\n",
       "   CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "0          1.158397                         0.498036   \n",
       "1          1.145199                         0.208736   \n",
       "2          1.000000                         0.500000   \n",
       "3          1.052803                         0.431748   \n",
       "4          1.000000                         0.236842   \n",
       "\n",
       "  CURRENT_LOAN_PAYMENT_RATE TOTAL_AMT_ANNUITY TOTAL_AMT_CREDIT  \\\n",
       "0                  0.060749     247829.081500       888586.065   \n",
       "1                  0.027598     292122.185803      2103502.500   \n",
       "2                  0.050000               NaN              NaN   \n",
       "3                  0.094941               NaN              NaN   \n",
       "4                  0.042623               NaN              NaN   \n",
       "\n",
       "  TOTAL_EFFORT_RATE TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "0          1.223847                 0.227890            0.278903   \n",
       "1          1.081934                 0.128357            0.138874   \n",
       "2               NaN                      NaN                 NaN   \n",
       "3               NaN                      NaN                 NaN   \n",
       "4               NaN                      NaN                 NaN   \n",
       "\n",
       "   DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "0            0.067329           202500.0  \n",
       "1            0.070862           135000.0  \n",
       "2            0.011814            67500.0  \n",
       "3            0.159905            67500.0  \n",
       "4            0.152418           121500.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e16ce3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0', 'SK_ID_CURR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c44e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']\n",
    "x = data.drop(['TARGET'], axis=1)\n",
    "baseline_y = baseline_data['TARGET']\n",
    "baseline_x = baseline_data.drop(['TARGET'], axis=1) # Note : categorical data already encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5b893e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 399)\n",
      "(307507,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b4fa2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91927\n",
       "1    0.08073\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look targets breakdown\n",
    "y.value_counts().apply(lambda x: x / y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939e334",
   "metadata": {},
   "source": [
    "We have very imbalanced classes, we will use StratifiedKFold for now. And see for SMOTE after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2557b7",
   "metadata": {},
   "source": [
    "# 3. Preprocessing <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783be02",
   "metadata": {},
   "source": [
    "## I - Cleaning <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "50247db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307507.000000</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>3.072290e+05</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>307229.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>2.163040e+05</td>\n",
       "      <td>2.163140e+05</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>216314.000000</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>3.075050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417047</td>\n",
       "      <td>1.687977e+05</td>\n",
       "      <td>5.990286e+05</td>\n",
       "      <td>27108.666786</td>\n",
       "      <td>5.383977e+05</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-16037.027271</td>\n",
       "      <td>-2384.142254</td>\n",
       "      <td>-4986.131376</td>\n",
       "      <td>-2994.201670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122994</td>\n",
       "      <td>0.399669</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>9.411559e+05</td>\n",
       "      <td>1.926691e+06</td>\n",
       "      <td>5.708165</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>0.609689</td>\n",
       "      <td>0.156860</td>\n",
       "      <td>9.310608e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.722119</td>\n",
       "      <td>2.371246e+05</td>\n",
       "      <td>4.024926e+05</td>\n",
       "      <td>14493.798379</td>\n",
       "      <td>3.694472e+05</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>4363.982424</td>\n",
       "      <td>2338.327666</td>\n",
       "      <td>3522.883030</td>\n",
       "      <td>1509.454566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124036</td>\n",
       "      <td>0.507927</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>5.921754e+06</td>\n",
       "      <td>2.459518e+06</td>\n",
       "      <td>33.373152</td>\n",
       "      <td>0.246091</td>\n",
       "      <td>3.542178</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>1.013739e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>4.050000e+04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-25229.000000</td>\n",
       "      <td>-17912.000000</td>\n",
       "      <td>-24672.000000</td>\n",
       "      <td>-7197.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>3.006000e+03</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.812500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16524.000000</td>\n",
       "      <td>2.385000e+05</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>-19682.000000</td>\n",
       "      <td>-3175.000000</td>\n",
       "      <td>-7479.500000</td>\n",
       "      <td>-4299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193802</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>9.718556e+04</td>\n",
       "      <td>7.524000e+05</td>\n",
       "      <td>0.640621</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>4.725000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471500e+05</td>\n",
       "      <td>5.135310e+05</td>\n",
       "      <td>24903.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-15750.000000</td>\n",
       "      <td>-1648.000000</td>\n",
       "      <td>-4504.000000</td>\n",
       "      <td>-3254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>0.306272</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.004183e+05</td>\n",
       "      <td>1.305000e+06</td>\n",
       "      <td>2.029257</td>\n",
       "      <td>0.116145</td>\n",
       "      <td>0.211615</td>\n",
       "      <td>0.118733</td>\n",
       "      <td>7.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>8.086500e+05</td>\n",
       "      <td>34596.000000</td>\n",
       "      <td>6.795000e+05</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-12413.000000</td>\n",
       "      <td>-767.000000</td>\n",
       "      <td>-2010.000000</td>\n",
       "      <td>-1720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198000</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>7.142913e+05</td>\n",
       "      <td>2.254457e+06</td>\n",
       "      <td>4.373481</td>\n",
       "      <td>0.189675</td>\n",
       "      <td>0.395364</td>\n",
       "      <td>0.219167</td>\n",
       "      <td>1.125000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>208.003328</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>6.802079e+08</td>\n",
       "      <td>3.356847e+08</td>\n",
       "      <td>3702.839475</td>\n",
       "      <td>95.097017</td>\n",
       "      <td>264.392053</td>\n",
       "      <td>0.728811</td>\n",
       "      <td>3.900000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  \\\n",
       "count  307507.000000      3.075070e+05  3.075070e+05  307495.000000   \n",
       "mean        0.417047      1.687977e+05  5.990286e+05   27108.666786   \n",
       "std         0.722119      2.371246e+05  4.024926e+05   14493.798379   \n",
       "min         0.000000      2.565000e+04  4.500000e+04    1615.500000   \n",
       "25%         0.000000      1.125000e+05  2.700000e+05   16524.000000   \n",
       "50%         0.000000      1.471500e+05  5.135310e+05   24903.000000   \n",
       "75%         1.000000      2.025000e+05  8.086500e+05   34596.000000   \n",
       "max        19.000000      1.170000e+08  4.050000e+06  258025.500000   \n",
       "\n",
       "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE     DAYS_BIRTH  \\\n",
       "count     3.072290e+05               307507.000000  307507.000000   \n",
       "mean      5.383977e+05                    0.020868  -16037.027271   \n",
       "std       3.694472e+05                    0.013831    4363.982424   \n",
       "min       4.050000e+04                    0.000290  -25229.000000   \n",
       "25%       2.385000e+05                    0.010006  -19682.000000   \n",
       "50%       4.500000e+05                    0.018850  -15750.000000   \n",
       "75%       6.795000e+05                    0.028663  -12413.000000   \n",
       "max       4.050000e+06                    0.072508   -7489.000000   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "count  252133.000000      307507.000000    307507.000000  ...   \n",
       "mean    -2384.142254       -4986.131376     -2994.201670  ...   \n",
       "std      2338.327666        3522.883030      1509.454566  ...   \n",
       "min    -17912.000000      -24672.000000     -7197.000000  ...   \n",
       "25%     -3175.000000       -7479.500000     -4299.000000  ...   \n",
       "50%     -1648.000000       -4504.000000     -3254.000000  ...   \n",
       "75%      -767.000000       -2010.000000     -1720.000000  ...   \n",
       "max         0.000000           0.000000         0.000000  ...   \n",
       "\n",
       "       CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "count     307229.000000                    307507.000000   \n",
       "mean           1.122994                         0.399669   \n",
       "std            0.124036                         0.507927   \n",
       "min            0.150000                         0.011801   \n",
       "25%            1.000000                         0.193802   \n",
       "50%            1.118800                         0.306272   \n",
       "75%            1.198000                         0.495376   \n",
       "max            6.000000                       208.003328   \n",
       "\n",
       "       CURRENT_LOAN_PAYMENT_RATE  TOTAL_AMT_ANNUITY  TOTAL_AMT_CREDIT  \\\n",
       "count              307495.000000       2.163040e+05      2.163140e+05   \n",
       "mean                    0.053695       9.411559e+05      1.926691e+06   \n",
       "std                     0.022481       5.921754e+06      2.459518e+06   \n",
       "min                     0.022073       3.006000e+03      4.500000e+04   \n",
       "25%                     0.036900       9.718556e+04      7.524000e+05   \n",
       "50%                     0.050000       3.004183e+05      1.305000e+06   \n",
       "75%                     0.064043       7.142913e+05      2.254457e+06   \n",
       "max                     0.124430       6.802079e+08      3.356847e+08   \n",
       "\n",
       "       TOTAL_EFFORT_RATE  TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "count      216304.000000             216314.000000       216304.000000   \n",
       "mean            5.708165                  0.154313            0.609689   \n",
       "std            33.373152                  0.246091            3.542178   \n",
       "min             0.003830                  0.000603            0.001404   \n",
       "25%             0.640621                  0.072865            0.093214   \n",
       "50%             2.029257                  0.116145            0.211615   \n",
       "75%             4.373481                  0.189675            0.395364   \n",
       "max          3702.839475                 95.097017          264.392053   \n",
       "\n",
       "       DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "count       252133.000000       3.075050e+05  \n",
       "mean             0.156860       9.310608e+04  \n",
       "std              0.133548       1.013739e+05  \n",
       "min             -0.000000       2.812500e+03  \n",
       "25%              0.056098       4.725000e+04  \n",
       "50%              0.118733       7.500000e+04  \n",
       "75%              0.219167       1.125000e+05  \n",
       "max              0.728811       3.900000e+07  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d5d1440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical and categorical columns\n",
    "categorical_cols = [col for col in x.columns if x[col].dtype == 'object']\n",
    "numerical_cols = list(x.drop(categorical_cols, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4507f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df contains 8877 infinite values\n"
     ]
    }
   ],
   "source": [
    "# Checking infinite values\n",
    "  \n",
    "count = np.isinf(x[numerical_cols]).values.sum()\n",
    "print(\"The df contains \" + str(count) + \" infinite values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "66d45e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace inf values by NaN\n",
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec914f7",
   "metadata": {},
   "source": [
    "## II - Split train/test and preprocessing <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "60cf4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5f848ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of preprocessing steps\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('stdscaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3974310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datas\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19248894",
   "metadata": {},
   "source": [
    "## III - Dimensionality reduction <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f888f4",
   "metadata": {},
   "source": [
    "To speed up our algorithms on our model selection, we will reduce the dimensionality of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "95f76a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions x_train before PCA reduction :  (246005, 670)\n",
      "Dimensions x_test before PCA reduction :  (61502, 670)\n",
      "\n",
      "Proceed PCA on train and test set - done in 21s\n",
      "Dimensions x_train after PCA reduction :  (246005, 289)\n",
      "Dimensions x_test after PCA reduction :  (61502, 289)\n"
     ]
    }
   ],
   "source": [
    "# PCA on processed data\n",
    "\n",
    "print(\"Dimensions x_train before PCA reduction : \", x_train_processed.shape)\n",
    "print(\"Dimensions x_test before PCA reduction : \", x_test_processed.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "\n",
    "print(\"\")\n",
    "with timer(\"Proceed PCA on train and test set\"):\n",
    "    x_train_pca = pca.fit_transform(x_train_processed)\n",
    "    x_test_pca = pca.transform(x_test_processed)\n",
    "\n",
    "print(\"Dimensions x_train after PCA reduction : \", x_train_pca.shape)\n",
    "print(\"Dimensions x_test after PCA reduction : \", x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a90f3",
   "metadata": {},
   "source": [
    "## IV - Creation of folds for cv <a class=\"anchor\" id=\"7-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2e115369",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(x_train_pca, y_train, num_folds=num_folds, stratified=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "77413351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 45234, 1: 3967})\n",
      "Counter({0: 45234, 1: 3967})\n",
      "Counter({0: 45233, 1: 3968})\n",
      "Counter({0: 45233, 1: 3968})\n",
      "Counter({0: 45233, 1: 3968})\n"
     ]
    }
   ],
   "source": [
    "# Look classs balance in each fold\n",
    "\n",
    "for i in range(5):\n",
    "   print(Counter(y_train.iloc[folds[i][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f302d2",
   "metadata": {},
   "source": [
    "# 4. Baseline model testing <a class=\"anchor\" id=\"8-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683b5ff",
   "metadata": {},
   "source": [
    "## I - Dummy classifiers <a class=\"anchor\" id=\"9-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0afbf1",
   "metadata": {},
   "source": [
    "### a. Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e841d3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_frequent</th>\n",
       "      <th>prior</th>\n",
       "      <th>stratified</th>\n",
       "      <th>uniform</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>5.070557</td>\n",
       "      <td>17.256768</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.013446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               most_frequent     prior  stratified    uniform  constant\n",
       "accuracy            0.919981  0.919981    0.853194   0.500376  0.919981\n",
       "f1                  0.000000  0.000000    0.079521   0.136565  0.000000\n",
       "precision           0.000000  0.000000    0.079795   0.079240  0.000000\n",
       "recall              0.000000  0.000000    0.079248   0.493777  0.000000\n",
       "roc_auc             0.500000  0.500000    0.499879   0.500000  0.500000\n",
       "cross_entropy       2.763748  2.763748    5.070557  17.256768  2.763748\n",
       "fit_time            0.016626  0.014415    0.008039   0.012216  0.013446\n",
       "predict_time        0.001482  0.000999    0.001896   0.001412  0.000870"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = test_dummy_classifiers(x_train_pca, y_train, valid_size=0.2, \n",
    "                                 strategies_list=None, random_state=random_state, constant=0, balance_class=False)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9fcc7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.499976\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(dummies.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5990c4",
   "metadata": {},
   "source": [
    "### b. Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fdfbdf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_frequent</th>\n",
       "      <th>prior</th>\n",
       "      <th>stratified</th>\n",
       "      <th>uniform</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.642914</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128392</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079778</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328677</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499461</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>12.333564</td>\n",
       "      <td>17.256768</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               most_frequent     prior  stratified    uniform  constant\n",
       "accuracy            0.919981  0.919981    0.642914   0.500376  0.919981\n",
       "f1                  0.000000  0.000000    0.128392   0.136565  0.000000\n",
       "precision           0.000000  0.000000    0.079778   0.079240  0.000000\n",
       "recall              0.000000  0.000000    0.328677   0.493777  0.000000\n",
       "roc_auc             0.500000  0.500000    0.499461   0.500000  0.500000\n",
       "cross_entropy       2.763748  2.763748   12.333564  17.256768  2.763748\n",
       "fit_time            0.006022  0.001100    0.000928   0.001024  0.001601\n",
       "predict_time        0.001698  0.000466    0.001782   0.000491  0.000528"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_2 = test_dummy_classifiers(x_train_pca, y_train, valid_size=0.2, \n",
    "                                   strategies_list=None, random_state=random_state, constant=0, balance_class=True)\n",
    "dummies_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "241723df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.499892\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(dummies_2.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559819",
   "metadata": {},
   "source": [
    "## II - Quick testing <a class=\"anchor\" id=\"10-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436c440",
   "metadata": {},
   "source": [
    "### a. Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ade35fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of some classifiers - done in 22795s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919798</td>\n",
       "      <td>0.915103</td>\n",
       "      <td>0.920063</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.508850</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.662433</td>\n",
       "      <td>0.577950</td>\n",
       "      <td>0.771007</td>\n",
       "      <td>0.767978</td>\n",
       "      <td>0.673001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.770066</td>\n",
       "      <td>2.932232</td>\n",
       "      <td>2.760942</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>422.415992</td>\n",
       "      <td>0.126682</td>\n",
       "      <td>123.843777</td>\n",
       "      <td>0.732317</td>\n",
       "      <td>20675.629150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>1.262353</td>\n",
       "      <td>41.642139</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>743.403910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compute_score_time</th>\n",
       "      <td>0.070560</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.045043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RandomForestClassifier  KNeighborsClassifier  \\\n",
       "accuracy                          0.919798              0.915103   \n",
       "f1                                0.000507              0.045693   \n",
       "precision                         0.090909              0.227273   \n",
       "recall                            0.000254              0.025400   \n",
       "roc_auc                           0.662433              0.577950   \n",
       "cross_entropy                     2.770066              2.932232   \n",
       "fit_time                        422.415992              0.126682   \n",
       "predict_time                      1.262353             41.642139   \n",
       "compute_score_time                0.070560              0.047518   \n",
       "\n",
       "                    LogisticRegression  RidgeClassifier           SVC  \n",
       "accuracy                      0.920063         0.919981      0.919981  \n",
       "f1                            0.055249         0.001015      0.000000  \n",
       "precision                     0.508850         0.500000      0.000000  \n",
       "recall                        0.029210         0.000508      0.000000  \n",
       "roc_auc                       0.771007         0.767978      0.673001  \n",
       "cross_entropy                 2.760942         2.763748      2.763748  \n",
       "fit_time                    123.843777         0.732317  20675.629150  \n",
       "predict_time                  0.040803         0.019151    743.403910  \n",
       "compute_score_time            0.046990         0.040441      0.045043  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test some models without hyperparameters optimization\n",
    "\n",
    "models_list = [\n",
    "    # 'GradientBoostingClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'KNeighborsClassifier',\n",
    "    # 'GaussianProcessClassifier', \n",
    "    'LogisticRegression', \n",
    "    'RidgeClassifier', \n",
    "    # 'SGDClassifier',\n",
    "    # 'LinearSVC', \n",
    "    # 'NuSVC', \n",
    "    'SVC', \n",
    "    # 'DecisionTreeClassifier'\n",
    "]\n",
    "\n",
    "with timer(\"Quick test of some classifiers\"):\n",
    "    quick_test_1 = quick_classifiers_test(x_train_pca, y_train, valid_size=0.2,models_list=models_list, \n",
    "                                          random_state=random_state, max_iter=10000, n_jobs=-1, balance_class=False)\n",
    "\n",
    "quick_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3e18e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.690474\n",
      "Max roc_auc : 0.771007\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(quick_test_1.iloc[4].mean()))\n",
    "print(\"Max roc_auc : {:.6f}\".format(quick_test_1.iloc[4].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf4b44",
   "metadata": {},
   "source": [
    "### b. Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3fd72f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of some classifiers - done in 1464s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.895043</td>\n",
       "      <td>0.687974</td>\n",
       "      <td>0.841345</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.859962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.193629</td>\n",
       "      <td>0.194628</td>\n",
       "      <td>0.310668</td>\n",
       "      <td>0.311547</td>\n",
       "      <td>0.312101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>0.238121</td>\n",
       "      <td>0.244913</td>\n",
       "      <td>0.257115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.471171</td>\n",
       "      <td>0.446787</td>\n",
       "      <td>0.427991</td>\n",
       "      <td>0.397003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.622611</td>\n",
       "      <td>0.770914</td>\n",
       "      <td>0.770269</td>\n",
       "      <td>0.763111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>3.625124</td>\n",
       "      <td>10.777218</td>\n",
       "      <td>5.479852</td>\n",
       "      <td>5.227829</td>\n",
       "      <td>4.836808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>60.890628</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>18.908819</td>\n",
       "      <td>0.173946</td>\n",
       "      <td>584.349935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.926250</td>\n",
       "      <td>11.538366</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>386.572186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compute_score_time</th>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.037641</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>0.055558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RandomForestClassifier  KNeighborsClassifier  \\\n",
       "accuracy                          0.895043              0.687974   \n",
       "f1                                0.193629              0.194628   \n",
       "precision                         0.251317              0.122645   \n",
       "recall                            0.157480              0.471171   \n",
       "roc_auc                           0.714894              0.622611   \n",
       "cross_entropy                     3.625124             10.777218   \n",
       "fit_time                         60.890628              0.019599   \n",
       "predict_time                      0.926250             11.538366   \n",
       "compute_score_time                0.036803              0.049717   \n",
       "\n",
       "                    LogisticRegression  RidgeClassifier         SVC  \n",
       "accuracy                      0.841345         0.848641    0.859962  \n",
       "f1                            0.310668         0.311547    0.312101  \n",
       "precision                     0.238121         0.244913    0.257115  \n",
       "recall                        0.446787         0.427991    0.397003  \n",
       "roc_auc                       0.770914         0.770269    0.763111  \n",
       "cross_entropy                 5.479852         5.227829    4.836808  \n",
       "fit_time                     18.908819         0.173946  584.349935  \n",
       "predict_time                  0.018744         0.018717  386.572186  \n",
       "compute_score_time            0.037641         0.041494    0.055558  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with timer(\"Quick test of some classifiers\"):\n",
    "    quick_test_2 = quick_classifiers_test(x_train_pca, y_train, valid_size=0.2,models_list=models_list, \n",
    "                                          random_state=random_state, max_iter=10000, n_jobs=-1, balance_class=True)\n",
    "\n",
    "quick_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dfcaff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.728360\n",
      "Max roc_auc : 0.770914\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(quick_test_2.iloc[4].mean()))\n",
    "print(\"Max roc_auc : {:.6f}\".format(quick_test_2.iloc[4].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf264f63",
   "metadata": {},
   "source": [
    "Balancing seems to improve our performances, we will apply it on further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9401c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_class = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab682f",
   "metadata": {},
   "source": [
    "# 5. Cross-validation model testing <a class=\"anchor\" id=\"11-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb689f",
   "metadata": {},
   "source": [
    "## I - Linear models <a class=\"anchor\" id=\"12-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9935415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 1.0}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 45s\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "64ff2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__alpha': 10}\n",
      "Best score on training set : 0.768\n",
      "Proceed RidgeClassifier - done in 31s\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'alpha' : np.linspace(1, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed RidgeClassifier\"):\n",
    "    RidgeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                           param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea998dd",
   "metadata": {},
   "source": [
    "## II - KNN <a class=\"anchor\" id=\"13-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "458a7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__n_neighbors': 10}\n",
      "Best score on training set : 0.646\n",
      "Proceed KNeighborsClassifier - done in 215s\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed KNeighborsClassifier\"):\n",
    "    KNeighborsClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64066bde",
   "metadata": {},
   "source": [
    "## III - SVM <a class=\"anchor\" id=\"14-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0c37646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LinearSVC - done in 2628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "\n",
    "model = LinearSVC(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LinearSVC\"):\n",
    "    LinearSVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                     param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "887aa048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 0.4}\n",
      "Best score on training set : 0.685\n",
      "Proceed SVC - done in 3122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "model = SVC(kernel='rbf', random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed SVC\"):\n",
    "    SVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                               param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3021e",
   "metadata": {},
   "source": [
    "## IV - Trees and ensemblist methods <a class=\"anchor\" id=\"15-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "359e2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
      "Best score on training set : 0.575\n",
      "Proceed DecisionTreeClassifier - done in 177s\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "param_grid = {'min_samples_split' : [2, 8], 'min_samples_leaf' : [1, 5]}\n",
    "\n",
    "with timer(\"Proceed DecisionTreeClassifier\"):\n",
    "    DecisionTreeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                  param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b694f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters on training set :\n",
      "{'n_estimators': 500}\n",
      "Best score on training set : 0.760\n",
      "Proceed GradientBoostingClassifier - done in 43891s\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier --> not tested in 2nd iteration (too long to train, 43891s iteration 1)\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state=random_state)\n",
    "# param_grid = {'n_estimators' : [10, 100, 500]}\n",
    "\n",
    "# with timer(\"Proceed GradientBoostingClassifier\"):\n",
    "    # GradientBoostingClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                      # param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b62c007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters on training set :\n",
      "{'model__n_estimators': 500}\n",
      "Best score on training set : 0.729\n",
      "Proceed RandomForestClassifier - done in 1642s\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "param_grid = {'n_estimators' : [10, 500]}\n",
    "\n",
    "with timer(\"Proceed RandomForestClassifier\"):\n",
    "    RandomForestClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                  param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b34e30",
   "metadata": {},
   "source": [
    "## V - Neural networks <a class=\"anchor\" id=\"16-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "bfcd7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test a standard binary classification NN model (activations hidden = relu, last activation = sigmoid) \n",
    "# and try to optimize hyperparameters (learning rate, nb neurons and layers)\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=0.001, input_shape=[289]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fa593ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d094814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 925us/step - loss: 0.2899 - auc: 0.5990\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2634 - auc: 0.7017\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 6s 904us/step - loss: 0.2540 - auc: 0.7344\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2496 - auc: 0.7489\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 6s 899us/step - loss: 0.2471 - auc: 0.7569\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 911us/step - loss: 0.2453 - auc: 0.7625\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 6s 898us/step - loss: 0.2439 - auc: 0.7670\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 898us/step - loss: 0.2427 - auc: 0.7705\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 905us/step - loss: 0.2417 - auc: 0.7734\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 895us/step - loss: 0.2409 - auc: 0.7758\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 894us/step - loss: 0.2895 - auc: 0.6054\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 882us/step - loss: 0.2611 - auc: 0.7067\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 886us/step - loss: 0.2531 - auc: 0.7360\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 887us/step - loss: 0.2493 - auc: 0.7492\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 885us/step - loss: 0.2470 - auc: 0.7567\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 896us/step - loss: 0.2452 - auc: 0.7623\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 881us/step - loss: 0.2439 - auc: 0.7665\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 888us/step - loss: 0.2428 - auc: 0.7697\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2418 - auc: 0.7727\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 887us/step - loss: 0.2409 - auc: 0.7755\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 901us/step - loss: 0.2894 - auc: 0.6072\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2608 - auc: 0.7079\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 6s 902us/step - loss: 0.2530 - auc: 0.7365\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2490 - auc: 0.7502\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 890us/step - loss: 0.2465 - auc: 0.7586\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2448 - auc: 0.7640\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 889us/step - loss: 0.2433 - auc: 0.7684\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 895us/step - loss: 0.2422 - auc: 0.7718\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 903us/step - loss: 0.2412 - auc: 0.7748\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 894us/step - loss: 0.2403 - auc: 0.7775\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 889us/step - loss: 0.2851 - auc: 0.6213\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 878us/step - loss: 0.2599 - auc: 0.7149\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 882us/step - loss: 0.2526 - auc: 0.7403\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 881us/step - loss: 0.2488 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 6s 908us/step - loss: 0.2464 - auc: 0.7594\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 951us/step - loss: 0.2447 - auc: 0.7648\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 6s 912us/step - loss: 0.2433 - auc: 0.7690\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 910us/step - loss: 0.2422 - auc: 0.7722\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 951us/step - loss: 0.2411 - auc: 0.7753\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 1ms/step - loss: 0.2402 - auc: 0.7781\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 872us/step - loss: 0.2871 - auc: 0.6196\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 872us/step - loss: 0.2601 - auc: 0.7141\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 878us/step - loss: 0.2525 - auc: 0.7405\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 880us/step - loss: 0.2489 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 876us/step - loss: 0.2465 - auc: 0.7593\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 902us/step - loss: 0.2449 - auc: 0.7643\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 880us/step - loss: 0.2436 - auc: 0.7683\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 883us/step - loss: 0.2426 - auc: 0.7713\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 950us/step - loss: 0.2417 - auc: 0.7743\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 901us/step - loss: 0.2407 - auc: 0.7769\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 523us/step - loss: 0.4803 - auc: 0.5947\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 524us/step - loss: 0.2962 - auc: 0.7061\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 531us/step - loss: 0.2659 - auc: 0.7399\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 526us/step - loss: 0.2556 - auc: 0.7519\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2508 - auc: 0.7573\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2483 - auc: 0.7609\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 529us/step - loss: 0.2468 - auc: 0.7627\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2458 - auc: 0.7642\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2451 - auc: 0.7654\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2447 - auc: 0.7664\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 526us/step - loss: 0.4809 - auc: 0.5837\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2976 - auc: 0.7011\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2670 - auc: 0.7366\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2564 - auc: 0.7492\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2515 - auc: 0.7555\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2487 - auc: 0.7591\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 516us/step - loss: 0.2471 - auc: 0.7614\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2461 - auc: 0.7633\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2454 - auc: 0.7645\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2449 - auc: 0.7655\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 520us/step - loss: 0.4857 - auc: 0.5701\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 531us/step - loss: 0.2969 - auc: 0.7064\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2662 - auc: 0.7407\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2558 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2511 - auc: 0.7571\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 530us/step - loss: 0.2486 - auc: 0.7604\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2470 - auc: 0.7625\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2460 - auc: 0.7640\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 527us/step - loss: 0.2453 - auc: 0.7651\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 528us/step - loss: 0.2449 - auc: 0.7659\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 519us/step - loss: 0.4867 - auc: 0.5940\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2970 - auc: 0.7070\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2663 - auc: 0.7411\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2559 - auc: 0.7526\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2512 - auc: 0.7580\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2486 - auc: 0.7614\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2471 - auc: 0.7633\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 523us/step - loss: 0.2461 - auc: 0.7646\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2453 - auc: 0.7658\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2448 - auc: 0.7667\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 516us/step - loss: 0.4858 - auc: 0.5991\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2979 - auc: 0.7065\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 519us/step - loss: 0.2665 - auc: 0.7402\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2559 - auc: 0.7524\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2511 - auc: 0.7579\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 524us/step - loss: 0.2486 - auc: 0.7612\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2470 - auc: 0.7631\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 518us/step - loss: 0.2461 - auc: 0.7642\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2454 - auc: 0.7656\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 505us/step - loss: 0.2449 - auc: 0.7663\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 792us/step - loss: 0.3048 - auc: 0.5652\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2704 - auc: 0.6747\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2601 - auc: 0.7128\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2547 - auc: 0.7312\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2515 - auc: 0.7421\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2494 - auc: 0.7491\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2478 - auc: 0.7543\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2464 - auc: 0.7584\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2454 - auc: 0.7616\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2445 - auc: 0.7645\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 814us/step - loss: 0.2985 - auc: 0.5791\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2684 - auc: 0.6858\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2591 - auc: 0.7179\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2543 - auc: 0.7334\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2513 - auc: 0.7429\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2494 - auc: 0.7492\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2478 - auc: 0.7543\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2466 - auc: 0.7581\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2456 - auc: 0.7612\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2447 - auc: 0.7639\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 824us/step - loss: 0.2917 - auc: 0.6201\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2659 - auc: 0.6954\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2584 - auc: 0.7214\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2541 - auc: 0.7352\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2514 - auc: 0.7439\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2494 - auc: 0.7501\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2480 - auc: 0.7547\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2467 - auc: 0.7586\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2457 - auc: 0.7619\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2448 - auc: 0.7645\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 798us/step - loss: 0.2953 - auc: 0.5856\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2682 - auc: 0.6847\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2591 - auc: 0.7172\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2543 - auc: 0.7334\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2514 - auc: 0.7431\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2494 - auc: 0.7494\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2479 - auc: 0.7542\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2467 - auc: 0.7581\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2457 - auc: 0.7614\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2447 - auc: 0.7642\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 786us/step - loss: 0.3016 - auc: 0.5824\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2702 - auc: 0.6789\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2606 - auc: 0.7133\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2555 - auc: 0.7304\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2523 - auc: 0.7405\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2501 - auc: 0.7475\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2484 - auc: 0.7525\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2470 - auc: 0.7569\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2458 - auc: 0.7604\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2449 - auc: 0.7632\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 707us/step - loss: 0.3044 - auc: 0.5718\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2691 - auc: 0.6715\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2615 - auc: 0.7054\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2571 - auc: 0.7234\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2541 - auc: 0.7345\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2520 - auc: 0.7423\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2503 - auc: 0.7478\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2491 - auc: 0.7518\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2481 - auc: 0.7550\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2472 - auc: 0.7578\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 706us/step - loss: 0.3052 - auc: 0.5819\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2711 - auc: 0.6647\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2637 - auc: 0.6988\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2591 - auc: 0.7185\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2559 - auc: 0.7304\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2535 - auc: 0.7387\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2517 - auc: 0.7445\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2503 - auc: 0.7488\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2492 - auc: 0.7524\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2482 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 696us/step - loss: 0.3561 - auc: 0.5091\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2758 - auc: 0.6151\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2688 - auc: 0.6672\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2639 - auc: 0.6947\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2601 - auc: 0.7129\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2570 - auc: 0.7257\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2546 - auc: 0.7350\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2527 - auc: 0.7419\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2512 - auc: 0.7471\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2500 - auc: 0.7512\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 704us/step - loss: 0.3248 - auc: 0.5735\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2669 - auc: 0.6808\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2598 - auc: 0.7125\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2560 - auc: 0.7281\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2535 - auc: 0.7377\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 749us/step - loss: 0.2517 - auc: 0.7445\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2503 - auc: 0.7493\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2491 - auc: 0.7530\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2481 - auc: 0.7561\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2472 - auc: 0.7588\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 704us/step - loss: 0.3067 - auc: 0.5641\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2724 - auc: 0.6585\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2645 - auc: 0.6940\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2598 - auc: 0.7138\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2567 - auc: 0.7268\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2543 - auc: 0.7358\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2525 - auc: 0.7424\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2511 - auc: 0.7475\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2499 - auc: 0.7514\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2488 - auc: 0.7545\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 792us/step - loss: 0.3142 - auc: 0.5397\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2781 - auc: 0.6420\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2674 - auc: 0.6860\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2610 - auc: 0.7102\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2567 - auc: 0.7255\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2537 - auc: 0.7353\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 799us/step - loss: 0.2516 - auc: 0.7426\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2499 - auc: 0.7478\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 796us/step - loss: 0.2486 - auc: 0.7518\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2475 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 811us/step - loss: 0.3000 - auc: 0.5843\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2729 - auc: 0.6660\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2641 - auc: 0.6998\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2587 - auc: 0.7184\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2552 - auc: 0.7302\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2527 - auc: 0.7384\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2509 - auc: 0.7447\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2495 - auc: 0.7494\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2483 - auc: 0.7531\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2474 - auc: 0.7561\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 798us/step - loss: 0.3004 - auc: 0.5811\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2730 - auc: 0.6661\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2639 - auc: 0.6996\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2587 - auc: 0.7181\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2552 - auc: 0.7299\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2527 - auc: 0.7385\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2509 - auc: 0.7447\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2494 - auc: 0.7493\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2482 - auc: 0.7533\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2472 - auc: 0.7565\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 800us/step - loss: 0.3123 - auc: 0.5734\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2722 - auc: 0.6692\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2631 - auc: 0.7035\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2579 - auc: 0.7221\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2544 - auc: 0.7338\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2520 - auc: 0.7414\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2501 - auc: 0.7475\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2486 - auc: 0.7521\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2475 - auc: 0.7557\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2465 - auc: 0.7589\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 768us/step - loss: 0.3040 - auc: 0.5674\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2761 - auc: 0.6510\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2665 - auc: 0.6900\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2605 - auc: 0.7121\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2565 - auc: 0.7260\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2536 - auc: 0.7358\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2515 - auc: 0.7429\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2499 - auc: 0.7479\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2487 - auc: 0.7521\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2476 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 764us/step - loss: 0.3311 - auc: 0.5485\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2892 - auc: 0.6091\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2796 - auc: 0.6439\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2734 - auc: 0.6674\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2690 - auc: 0.6842\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2656 - auc: 0.6968\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2629 - auc: 0.7068\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2605 - auc: 0.7149\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2586 - auc: 0.7214\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2570 - auc: 0.7268\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 769us/step - loss: 0.3299 - auc: 0.5374\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2893 - auc: 0.6009\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2796 - auc: 0.6390\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2732 - auc: 0.6644\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2684 - auc: 0.6829\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2648 - auc: 0.6966\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2619 - auc: 0.7072\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2596 - auc: 0.7156\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2577 - auc: 0.7222\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2561 - auc: 0.7277\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 765us/step - loss: 0.3260 - auc: 0.5403\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2915 - auc: 0.5932\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2827 - auc: 0.6263\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2768 - auc: 0.6499\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2723 - auc: 0.6673\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2687 - auc: 0.6812\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2657 - auc: 0.6923\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2632 - auc: 0.7014\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2612 - auc: 0.7092\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2594 - auc: 0.7157\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 760us/step - loss: 0.3294 - auc: 0.5622\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2850 - auc: 0.6209\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2766 - auc: 0.6517\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2713 - auc: 0.6724\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 762us/step - loss: 0.2674 - auc: 0.6874\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2644 - auc: 0.6987\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2619 - auc: 0.7076\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2599 - auc: 0.7148\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2582 - auc: 0.7209\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2567 - auc: 0.7256\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 763us/step - loss: 0.3239 - auc: 0.5082\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2939 - auc: 0.5848\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2835 - auc: 0.6283\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2766 - auc: 0.6561\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2715 - auc: 0.6756\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2676 - auc: 0.6904\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2645 - auc: 0.7012\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2619 - auc: 0.7100\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2598 - auc: 0.7170\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2580 - auc: 0.7230\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 813us/step - loss: 0.2573 - auc: 0.7258\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2441 - auc: 0.7669\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2407 - auc: 0.7771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2384 - auc: 0.7841\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2364 - auc: 0.7895\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2350 - auc: 0.7937\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2331 - auc: 0.7986\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2316 - auc: 0.8027\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2299 - auc: 0.8064\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2279 - auc: 0.8112\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 828us/step - loss: 0.2590 - auc: 0.7213\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2445 - auc: 0.7656\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2407 - auc: 0.7767\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 823us/step - loss: 0.2385 - auc: 0.7827\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2368 - auc: 0.7880\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2348 - auc: 0.7928\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 829us/step - loss: 0.2331 - auc: 0.7975\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2311 - auc: 0.8027\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2295 - auc: 0.8067\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 828us/step - loss: 0.2279 - auc: 0.8109\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 816us/step - loss: 0.2591 - auc: 0.7191\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2445 - auc: 0.7659\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2409 - auc: 0.7766\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2384 - auc: 0.7835\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2363 - auc: 0.7895\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 870us/step - loss: 0.2346 - auc: 0.7943\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 838us/step - loss: 0.2330 - auc: 0.7987\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 837us/step - loss: 0.2310 - auc: 0.8038\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2295 - auc: 0.8078\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2278 - auc: 0.8122\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 814us/step - loss: 0.2571 - auc: 0.7257\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2442 - auc: 0.7675\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2406 - auc: 0.7775\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2387 - auc: 0.7836\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2364 - auc: 0.7893\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2346 - auc: 0.7942\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2331 - auc: 0.7984\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2315 - auc: 0.8029\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2300 - auc: 0.8064\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2283 - auc: 0.8107\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 820us/step - loss: 0.2590 - auc: 0.7205\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2444 - auc: 0.7661\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2411 - auc: 0.7762\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2387 - auc: 0.7831\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2367 - auc: 0.7886\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2349 - auc: 0.7938\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 826us/step - loss: 0.2333 - auc: 0.7977\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2315 - auc: 0.8022\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2300 - auc: 0.8062\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2285 - auc: 0.8104\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 779us/step - loss: 0.3123 - auc: 0.5608\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2785 - auc: 0.6457\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2683 - auc: 0.6837\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2620 - auc: 0.7065\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2578 - auc: 0.7214\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2546 - auc: 0.7320\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2522 - auc: 0.7399\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2504 - auc: 0.7459\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2488 - auc: 0.7505\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2477 - auc: 0.7543\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 769us/step - loss: 0.3062 - auc: 0.5695\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2741 - auc: 0.6653\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2650 - auc: 0.6984\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2595 - auc: 0.7166\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2559 - auc: 0.7291\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2534 - auc: 0.7376\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2515 - auc: 0.7439\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2501 - auc: 0.7485\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2489 - auc: 0.7521\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2479 - auc: 0.7553\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 777us/step - loss: 0.3100 - auc: 0.5476\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2803 - auc: 0.6379\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2691 - auc: 0.6807\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2623 - auc: 0.7058\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2578 - auc: 0.7213\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2547 - auc: 0.7318\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2525 - auc: 0.7395\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2508 - auc: 0.7449\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2494 - auc: 0.7492\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2482 - auc: 0.7529\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 775us/step - loss: 0.3073 - auc: 0.5546\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2761 - auc: 0.6517\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2665 - auc: 0.6907\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2608 - auc: 0.7121\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2570 - auc: 0.7257\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2543 - auc: 0.7346\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2522 - auc: 0.7415\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2506 - auc: 0.7466\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2494 - auc: 0.7506\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2483 - auc: 0.7540\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 797us/step - loss: 0.2990 - auc: 0.5905\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2763 - auc: 0.6581\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2674 - auc: 0.6901\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2618 - auc: 0.7091\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2580 - auc: 0.7219\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2552 - auc: 0.7314\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2531 - auc: 0.7380\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2514 - auc: 0.7436\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2499 - auc: 0.7478\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2488 - auc: 0.7517\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 707us/step - loss: 0.3086 - auc: 0.5781\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2640 - auc: 0.6923\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2555 - auc: 0.7278\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2512 - auc: 0.7434\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2487 - auc: 0.7514\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2472 - auc: 0.7564\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2461 - auc: 0.7604\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2452 - auc: 0.7629\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2445 - auc: 0.7653\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2439 - auc: 0.7670\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 9s 701us/step - loss: 0.3051 - auc: 0.5948\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2634 - auc: 0.6974\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2565 - auc: 0.7264\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2525 - auc: 0.7412\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2498 - auc: 0.7499\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 714us/step - loss: 0.2481 - auc: 0.7554\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2467 - auc: 0.7597\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2457 - auc: 0.7628\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 723us/step - loss: 0.2449 - auc: 0.7655\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2441 - auc: 0.7675\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 720us/step - loss: 0.2909 - auc: 0.6060\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2640 - auc: 0.6983\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2576 - auc: 0.7250\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2542 - auc: 0.7378\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 715us/step - loss: 0.2519 - auc: 0.7462\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2503 - auc: 0.7518\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2492 - auc: 0.7558\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2482 - auc: 0.7588\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2472 - auc: 0.7618\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 711us/step - loss: 0.2465 - auc: 0.7638\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 695us/step - loss: 0.2937 - auc: 0.6031\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2636 - auc: 0.6971\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2576 - auc: 0.7238\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2542 - auc: 0.7377\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2519 - auc: 0.7461\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2502 - auc: 0.7519\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 714us/step - loss: 0.2489 - auc: 0.7560\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2477 - auc: 0.7594\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2467 - auc: 0.7623\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2459 - auc: 0.7644\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 686us/step - loss: 0.2911 - auc: 0.6029\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 693us/step - loss: 0.2635 - auc: 0.6973\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2568 - auc: 0.7258\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2531 - auc: 0.7399\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2507 - auc: 0.7480\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2491 - auc: 0.7533\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2478 - auc: 0.7573\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2467 - auc: 0.7604\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2458 - auc: 0.7630\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2451 - auc: 0.7652\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 815us/step - loss: 0.3088 - auc: 0.5516\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2824 - auc: 0.6219\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2740 - auc: 0.6581\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2683 - auc: 0.6815\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 828us/step - loss: 0.2639 - auc: 0.6988\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2605 - auc: 0.7118\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2577 - auc: 0.7222\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 835us/step - loss: 0.2554 - auc: 0.7303\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2536 - auc: 0.7365\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2520 - auc: 0.7415\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 812us/step - loss: 0.3195 - auc: 0.5226\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2836 - auc: 0.6087\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2736 - auc: 0.6549\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2671 - auc: 0.6832\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2623 - auc: 0.7028\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2587 - auc: 0.7165\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2559 - auc: 0.7269\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2538 - auc: 0.7342\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2521 - auc: 0.7404\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2507 - auc: 0.7452\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 815us/step - loss: 0.3063 - auc: 0.5532\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2781 - auc: 0.6401\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2696 - auc: 0.6771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2643 - auc: 0.6976\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2606 - auc: 0.7116\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2578 - auc: 0.7218\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 830us/step - loss: 0.2556 - auc: 0.7294\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2539 - auc: 0.7354\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2524 - auc: 0.7405\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2512 - auc: 0.7444\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 812us/step - loss: 0.3136 - auc: 0.5384\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2787 - auc: 0.6357\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2691 - auc: 0.6774\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2633 - auc: 0.7007\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2592 - auc: 0.7158\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2563 - auc: 0.7263\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2541 - auc: 0.7340\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2523 - auc: 0.7401\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2509 - auc: 0.7450\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2497 - auc: 0.7490\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 809us/step - loss: 0.3076 - auc: 0.5508\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2796 - auc: 0.6383\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2701 - auc: 0.6771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2641 - auc: 0.6991\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2599 - auc: 0.7137\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2568 - auc: 0.7243\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2544 - auc: 0.7320\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 799us/step - loss: 0.2526 - auc: 0.7384\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2511 - auc: 0.7431\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2500 - auc: 0.7469\n",
      "Epoch 1/10\n",
      "7688/7688 [==============================] - 8s 509us/step - loss: 0.4499 - auc: 0.6176\n",
      "Epoch 2/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2818 - auc: 0.7227\n",
      "Epoch 3/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2587 - auc: 0.7473\n",
      "Epoch 4/10\n",
      "7688/7688 [==============================] - 4s 507us/step - loss: 0.2514 - auc: 0.7560\n",
      "Epoch 5/10\n",
      "7688/7688 [==============================] - 4s 510us/step - loss: 0.2483 - auc: 0.7600\n",
      "Epoch 6/10\n",
      "7688/7688 [==============================] - 4s 507us/step - loss: 0.2466 - auc: 0.7627\n",
      "Epoch 7/10\n",
      "7688/7688 [==============================] - 4s 505us/step - loss: 0.2456 - auc: 0.7642\n",
      "Epoch 8/10\n",
      "7688/7688 [==============================] - 4s 509us/step - loss: 0.2450 - auc: 0.7655\n",
      "Epoch 9/10\n",
      "7688/7688 [==============================] - 4s 541us/step - loss: 0.2446 - auc: 0.7662\n",
      "Epoch 10/10\n",
      "7688/7688 [==============================] - 4s 503us/step - loss: 0.2442 - auc: 0.7671\n",
      "Proceed NeuralNetwork - done in 2813s\n"
     ]
    }
   ],
   "source": [
    "# Testing hyperparameters\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.linspace(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "# Testing model parameters\n",
    "nn_clf = RandomizedSearchCV(keras_clf, param_distribs, n_iter=10, \n",
    "                            cv=folds, scoring=optimized_metric, random_state=random_state)\n",
    "\n",
    "with timer(\"Proceed NeuralNetwork\"):\n",
    "    nn_clf.fit(x_train_pca, y_train, epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "de14514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters on training set :\n",
      "{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}\n",
      "Best score on training set : 0.764\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters on training set :\")\n",
    "print(nn_clf.best_params_)\n",
    "print(\"Best score on training set : {:.3f}\".format(nn_clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636224ce",
   "metadata": {},
   "source": [
    "## VI - Compare <a class=\"anchor\" id=\"17-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b7f7cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores in this iteration\n",
    "\n",
    "cv_clfs = {\n",
    "    'LogisticRegression' : LogisticRegression_clf,\n",
    "    'RidgeClassifier' : RidgeClassifier_clf,\n",
    "    'KNeighborsClassifier' : KNeighborsClassifier_clf,\n",
    "    'LinearSVC' : LinearSVC_clf,\n",
    "    'SVC' : SVC_clf,\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier_clf,\n",
    "    # 'GradientBoostingClassifier' : GradientBoostingClassifier_clf,\n",
    "    'RandomForestClassifier' : RandomForestClassifier_clf,\n",
    "    'NeuralNetwork' : nn_clf,\n",
    "}\n",
    "\n",
    "iteration_2 = pd.DataFrame()\n",
    "\n",
    "for key, clf in cv_clfs.items():\n",
    "    iteration_2[key] = [clf.best_score_, clf.best_params_]\n",
    "    \n",
    "iteration_2.index = ['best_score_ : ' + optimized_metric, 'best_params_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d9ae4283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>SVC</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>NeuralNetwork</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score_ : roc_auc</th>\n",
       "      <td>0.768028</td>\n",
       "      <td>0.767798</td>\n",
       "      <td>0.645989</td>\n",
       "      <td>0.768115</td>\n",
       "      <td>0.685251</td>\n",
       "      <td>0.575201</td>\n",
       "      <td>0.728944</td>\n",
       "      <td>0.763832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params_</th>\n",
       "      <td>{'model__C': 1.0}</td>\n",
       "      <td>{'model__alpha': 10}</td>\n",
       "      <td>{'model__n_neighbors': 10}</td>\n",
       "      <td>{'model__C': 0.1}</td>\n",
       "      <td>{'model__C': 0.4}</td>\n",
       "      <td>{'model__min_samples_leaf': 5, 'model__min_samples_split': 2}</td>\n",
       "      <td>{'model__n_estimators': 500}</td>\n",
       "      <td>{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LogisticRegression       RidgeClassifier  \\\n",
       "best_score_ : roc_auc           0.768028              0.767798   \n",
       "best_params_           {'model__C': 1.0}  {'model__alpha': 10}   \n",
       "\n",
       "                             KNeighborsClassifier          LinearSVC  \\\n",
       "best_score_ : roc_auc                    0.645989           0.768115   \n",
       "best_params_           {'model__n_neighbors': 10}  {'model__C': 0.1}   \n",
       "\n",
       "                                     SVC  \\\n",
       "best_score_ : roc_auc           0.685251   \n",
       "best_params_           {'model__C': 0.4}   \n",
       "\n",
       "                                                              DecisionTreeClassifier  \\\n",
       "best_score_ : roc_auc                                                       0.575201   \n",
       "best_params_           {'model__min_samples_leaf': 5, 'model__min_samples_split': 2}   \n",
       "\n",
       "                             RandomForestClassifier  \\\n",
       "best_score_ : roc_auc                      0.728944   \n",
       "best_params_           {'model__n_estimators': 500}   \n",
       "\n",
       "                                                                                                  NeuralNetwork  \n",
       "best_score_ : roc_auc                                                                                  0.763832  \n",
       "best_params_           {'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c9cf1577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC                 0.768115\n",
       "LogisticRegression        0.768028\n",
       "RidgeClassifier           0.767798\n",
       "NeuralNetwork             0.763832\n",
       "RandomForestClassifier    0.728944\n",
       "SVC                       0.685251\n",
       "KNeighborsClassifier      0.645989\n",
       "DecisionTreeClassifier    0.575201\n",
       "Name: best_score_ : roc_auc, dtype: object"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_2.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2a21dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_2.to_csv('./Scores/iteration_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ea1c4",
   "metadata": {},
   "source": [
    "# 6. Selected model fine tuning and interpretation <a class=\"anchor\" id=\"18-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddee0aa",
   "metadata": {},
   "source": [
    "## I - Fine tuning <a class=\"anchor\" id=\"19-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed0a19",
   "metadata": {},
   "source": [
    "### a. With lbfgs solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "40fe20e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 2.3000000000000003, 'model__class_weight': None}\n",
      "Best score on training set : 0.769\n",
      "Proceed LogisticRegression - done in 248s\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : same test as model selection with more parameters\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='l2', solver='lbfgs')\n",
    "param_grid = {\n",
    "    'C' : np.linspace(0.1, 10, num=10),\n",
    "    'class_weight' : [None, 'balanced']\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_1 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "88d9082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 1.9444444444444444}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 122s\n"
     ]
    }
   ],
   "source": [
    "# Test 2 : we keep class_weight=None and test other values of C centered in our result\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='l2', solver='lbfgs', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(1.5, 3.5, num=10),\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_2 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9dfa40",
   "metadata": {},
   "source": [
    "### b. With saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "34f4ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 4.0, 'model__l1_ratio': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 20467s\n"
     ]
    }
   ],
   "source": [
    "# Test 3 : solver saga with different penalties ratios \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='elasticnet', solver='saga', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(1, 5, num=5),\n",
    "    'l1_ratio' : np.linspace(0, 1, num=11)\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_3 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "cde65ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 4.5, 'model__l1_ratio': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 4418s\n"
     ]
    }
   ],
   "source": [
    "# Test 4 : centered search on previous results\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='elasticnet', solver='saga', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(3.5, 4.5, num=3),\n",
    "    'l1_ratio' : np.linspace(0.05, 0.15, num=3)\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_4 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846727ae",
   "metadata": {},
   "source": [
    "### c. With liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a6c6818c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 3.4000000000000004, 'model__penalty': 'l2'}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 716s\n"
     ]
    }
   ],
   "source": [
    "# Test 5 : solver liblinear with l1 and l2 penalties \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', solver='liblinear', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(0.1, 10, num=10),\n",
    "    'penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_5 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c1c0b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 3.5}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 141s\n"
     ]
    }
   ],
   "source": [
    "# Test 6 : centered search on previous results \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', solver='liblinear', class_weight=None, penalty='l2')\n",
    "param_grid = {\n",
    "    'C' : np.linspace(2.5, 4.5, num=5),\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_6 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369386b",
   "metadata": {},
   "source": [
    "### d. Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "68469a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores in this iteration\n",
    "\n",
    "models = [LogisticRegression_clf_1, LogisticRegression_clf_2, LogisticRegression_clf_3,\n",
    "LogisticRegression_clf_4, LogisticRegression_clf_5, LogisticRegression_clf_6]\n",
    "\n",
    "fine_tuning = pd.DataFrame()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    fine_tuning['LogisticRegression_clf_{}'.format(i+1)] = [model.best_score_, model.best_params_]\n",
    "    \n",
    "fine_tuning.index = ['best_score_ : ' + optimized_metric, 'best_params_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2015e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_clf_1    0.768558\n",
       "LogisticRegression_clf_3    0.768387\n",
       "LogisticRegression_clf_5     0.76834\n",
       "LogisticRegression_clf_2    0.768197\n",
       "LogisticRegression_clf_6    0.768014\n",
       "LogisticRegression_clf_4    0.767996\n",
       "Name: best_score_ : roc_auc, dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee0813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0be7513",
   "metadata": {},
   "source": [
    "Valeurs testées première itération (cleaned_data_1):\n",
    "- LogisticRegression : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.1 -> tester plus petit\n",
    "- RidgeClassifier : {'alpha' : np.linspace(1, 10, num=4, dtype=int)}, best : alpha = 10 -> tester plus grand\n",
    "- KNeighborsClassifier : {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}, best : n_neighbors = 10 > tester plus grand\n",
    "- LinearSVC : {'penalty' : ['l1', 'l2'], 'C' : np.linspace(0.1, 1, num=4)}, bests :\n",
    "    - C = 0.7 --> tester valeurs autour\n",
    "    - penalty = l2 --> conserver\n",
    "- SVC : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.4 -> tester valeurs autour\n",
    "- DecisionTreeClassifier : {'min_samples_split' : [2, 4, 8], 'min_samples_leaf' : [1, 3, 5]}, bests :\n",
    "    - min_samples_split = 2 --> conserver\n",
    "    - min_samples_leaf = 5 --> tester plus grand\n",
    "- GradientBoostingClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand\n",
    "- RandomForestClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
