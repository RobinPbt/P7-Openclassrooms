{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb37a03",
   "metadata": {},
   "source": [
    "# Table of Contents --> TBU\n",
    "\n",
    "1. [Global parameters](#1-bullet) <br>\n",
    "    <br>\n",
    "    \n",
    "2. [Loading datas](#2-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "3. [Preprocessing](#3-bullet) <br>\n",
    "    I - [Cleaning](#4-bullet) <br>\n",
    "    II - [Split train/test and preprocessing](#5-bullet) <br>\n",
    "    III - [Dimensionality reduction](#6-bullet) <br>\n",
    "    IV - [Creation of folds for cv](#7-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "4. [Baseline model testing](#8-bullet) <br>\n",
    "    I - [Dummy classifiers ](#9-bullet) <br>\n",
    "    II - [Quick testing](#10-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "5. [Cross-validation model testing](#11-bullet) <br>\n",
    "    I - [Linear models](#12-bullet) <br>\n",
    "    II - [KNN](#13-bullet) <br>\n",
    "    III - [SVM](#14-bullet) <br>\n",
    "    IV - [Trees and ensemblist methods](#15-bullet) <br>\n",
    "    V - [Neural networks](#16-bullet) <br>\n",
    "    VI - [Compare](#17-bullet) <br>\n",
    "    <br>\n",
    "    \n",
    "6. [Selected model fine tuning](#18-bullet) <br>\n",
    "    I - [Fine tuning](#19-bullet) <br>\n",
    "    II - [Business optimization](#20-bullet) <br>\n",
    "    III - [Features importance](#21-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "7. [xx](#xx-bullet) <br>\n",
    "    I - [xx](#xx-bullet) <br>\n",
    "    II - [xx](#xx-bullet) <br>\n",
    "    III - [xx](#xx-bullet) <br>\n",
    "    <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702077a",
   "metadata": {},
   "source": [
    "# 1. Global parameters <a class=\"anchor\" id=\"1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "40275ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General input\n",
    "random_state = 50 \n",
    "\n",
    "# Cross-validation\n",
    "optimized_metric = 'roc_auc' \n",
    "num_folds = 5\n",
    "stratified = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c16c80",
   "metadata": {},
   "source": [
    "# 2. Loading datas <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a30bce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import timeit\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "# Project specific functions\n",
    "from P7_functions import *\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import manifold, decomposition\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import imblearn\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e839d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "74f2bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_csv('./Clean_datas/baseline_data.csv', sep=\",\")\n",
    "data = pd.read_csv('./Clean_datas/clean_data_1.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "32fb710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158397</td>\n",
       "      <td>0.498036</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>247829.081500</td>\n",
       "      <td>888586.065</td>\n",
       "      <td>1.223847</td>\n",
       "      <td>0.227890</td>\n",
       "      <td>0.278903</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>202500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145199</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>292122.185803</td>\n",
       "      <td>2103502.500</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>0.128357</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052803</td>\n",
       "      <td>0.431748</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>121500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0      100002       1         Cash loans           M            N   \n",
       "1           1      100003       0         Cash loans           F            N   \n",
       "2           2      100004       0    Revolving loans           M            Y   \n",
       "3           3      100006       0         Cash loans           F            N   \n",
       "4           4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  ...  \\\n",
       "0               Y             0          202500.0    406597.5  ...   \n",
       "1               N             0          270000.0   1293502.5  ...   \n",
       "2               Y             0           67500.0    135000.0  ...   \n",
       "3               Y             0          135000.0    312682.5  ...   \n",
       "4               Y             0          121500.0    513000.0  ...   \n",
       "\n",
       "   CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "0          1.158397                         0.498036   \n",
       "1          1.145199                         0.208736   \n",
       "2          1.000000                         0.500000   \n",
       "3          1.052803                         0.431748   \n",
       "4          1.000000                         0.236842   \n",
       "\n",
       "  CURRENT_LOAN_PAYMENT_RATE TOTAL_AMT_ANNUITY TOTAL_AMT_CREDIT  \\\n",
       "0                  0.060749     247829.081500       888586.065   \n",
       "1                  0.027598     292122.185803      2103502.500   \n",
       "2                  0.050000               NaN              NaN   \n",
       "3                  0.094941               NaN              NaN   \n",
       "4                  0.042623               NaN              NaN   \n",
       "\n",
       "  TOTAL_EFFORT_RATE TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "0          1.223847                 0.227890            0.278903   \n",
       "1          1.081934                 0.128357            0.138874   \n",
       "2               NaN                      NaN                 NaN   \n",
       "3               NaN                      NaN                 NaN   \n",
       "4               NaN                      NaN                 NaN   \n",
       "\n",
       "   DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "0            0.067329           202500.0  \n",
       "1            0.070862           135000.0  \n",
       "2            0.011814            67500.0  \n",
       "3            0.159905            67500.0  \n",
       "4            0.152418           121500.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e16ce3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0', 'SK_ID_CURR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c44e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']\n",
    "x = data.drop(['TARGET'], axis=1)\n",
    "baseline_y = baseline_data['TARGET']\n",
    "baseline_x = baseline_data.drop(['TARGET'], axis=1) # Note : categorical data already encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5b893e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 399)\n",
      "(307507,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b4fa2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91927\n",
       "1    0.08073\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look targets breakdown\n",
    "y.value_counts().apply(lambda x: x / y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939e334",
   "metadata": {},
   "source": [
    "We have very imbalanced classes, we will use StratifiedKFold for now. And see for SMOTE after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2557b7",
   "metadata": {},
   "source": [
    "# 3. Preprocessing <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783be02",
   "metadata": {},
   "source": [
    "## I - Cleaning <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "50247db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307507.000000</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>3.072290e+05</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>307229.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>2.163040e+05</td>\n",
       "      <td>2.163140e+05</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>216314.000000</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>3.075050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417047</td>\n",
       "      <td>1.687977e+05</td>\n",
       "      <td>5.990286e+05</td>\n",
       "      <td>27108.666786</td>\n",
       "      <td>5.383977e+05</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-16037.027271</td>\n",
       "      <td>-2384.142254</td>\n",
       "      <td>-4986.131376</td>\n",
       "      <td>-2994.201670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122994</td>\n",
       "      <td>0.399669</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>9.411559e+05</td>\n",
       "      <td>1.926691e+06</td>\n",
       "      <td>5.708165</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>0.609689</td>\n",
       "      <td>0.156860</td>\n",
       "      <td>9.310608e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.722119</td>\n",
       "      <td>2.371246e+05</td>\n",
       "      <td>4.024926e+05</td>\n",
       "      <td>14493.798379</td>\n",
       "      <td>3.694472e+05</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>4363.982424</td>\n",
       "      <td>2338.327666</td>\n",
       "      <td>3522.883030</td>\n",
       "      <td>1509.454566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124036</td>\n",
       "      <td>0.507927</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>5.921754e+06</td>\n",
       "      <td>2.459518e+06</td>\n",
       "      <td>33.373152</td>\n",
       "      <td>0.246091</td>\n",
       "      <td>3.542178</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>1.013739e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>4.050000e+04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-25229.000000</td>\n",
       "      <td>-17912.000000</td>\n",
       "      <td>-24672.000000</td>\n",
       "      <td>-7197.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>3.006000e+03</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.812500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16524.000000</td>\n",
       "      <td>2.385000e+05</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>-19682.000000</td>\n",
       "      <td>-3175.000000</td>\n",
       "      <td>-7479.500000</td>\n",
       "      <td>-4299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193802</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>9.718556e+04</td>\n",
       "      <td>7.524000e+05</td>\n",
       "      <td>0.640621</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>4.725000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471500e+05</td>\n",
       "      <td>5.135310e+05</td>\n",
       "      <td>24903.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-15750.000000</td>\n",
       "      <td>-1648.000000</td>\n",
       "      <td>-4504.000000</td>\n",
       "      <td>-3254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>0.306272</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.004183e+05</td>\n",
       "      <td>1.305000e+06</td>\n",
       "      <td>2.029257</td>\n",
       "      <td>0.116145</td>\n",
       "      <td>0.211615</td>\n",
       "      <td>0.118733</td>\n",
       "      <td>7.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>8.086500e+05</td>\n",
       "      <td>34596.000000</td>\n",
       "      <td>6.795000e+05</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-12413.000000</td>\n",
       "      <td>-767.000000</td>\n",
       "      <td>-2010.000000</td>\n",
       "      <td>-1720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198000</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>7.142913e+05</td>\n",
       "      <td>2.254457e+06</td>\n",
       "      <td>4.373481</td>\n",
       "      <td>0.189675</td>\n",
       "      <td>0.395364</td>\n",
       "      <td>0.219167</td>\n",
       "      <td>1.125000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>208.003328</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>6.802079e+08</td>\n",
       "      <td>3.356847e+08</td>\n",
       "      <td>3702.839475</td>\n",
       "      <td>95.097017</td>\n",
       "      <td>264.392053</td>\n",
       "      <td>0.728811</td>\n",
       "      <td>3.900000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  \\\n",
       "count  307507.000000      3.075070e+05  3.075070e+05  307495.000000   \n",
       "mean        0.417047      1.687977e+05  5.990286e+05   27108.666786   \n",
       "std         0.722119      2.371246e+05  4.024926e+05   14493.798379   \n",
       "min         0.000000      2.565000e+04  4.500000e+04    1615.500000   \n",
       "25%         0.000000      1.125000e+05  2.700000e+05   16524.000000   \n",
       "50%         0.000000      1.471500e+05  5.135310e+05   24903.000000   \n",
       "75%         1.000000      2.025000e+05  8.086500e+05   34596.000000   \n",
       "max        19.000000      1.170000e+08  4.050000e+06  258025.500000   \n",
       "\n",
       "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE     DAYS_BIRTH  \\\n",
       "count     3.072290e+05               307507.000000  307507.000000   \n",
       "mean      5.383977e+05                    0.020868  -16037.027271   \n",
       "std       3.694472e+05                    0.013831    4363.982424   \n",
       "min       4.050000e+04                    0.000290  -25229.000000   \n",
       "25%       2.385000e+05                    0.010006  -19682.000000   \n",
       "50%       4.500000e+05                    0.018850  -15750.000000   \n",
       "75%       6.795000e+05                    0.028663  -12413.000000   \n",
       "max       4.050000e+06                    0.072508   -7489.000000   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "count  252133.000000      307507.000000    307507.000000  ...   \n",
       "mean    -2384.142254       -4986.131376     -2994.201670  ...   \n",
       "std      2338.327666        3522.883030      1509.454566  ...   \n",
       "min    -17912.000000      -24672.000000     -7197.000000  ...   \n",
       "25%     -3175.000000       -7479.500000     -4299.000000  ...   \n",
       "50%     -1648.000000       -4504.000000     -3254.000000  ...   \n",
       "75%      -767.000000       -2010.000000     -1720.000000  ...   \n",
       "max         0.000000           0.000000         0.000000  ...   \n",
       "\n",
       "       CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "count     307229.000000                    307507.000000   \n",
       "mean           1.122994                         0.399669   \n",
       "std            0.124036                         0.507927   \n",
       "min            0.150000                         0.011801   \n",
       "25%            1.000000                         0.193802   \n",
       "50%            1.118800                         0.306272   \n",
       "75%            1.198000                         0.495376   \n",
       "max            6.000000                       208.003328   \n",
       "\n",
       "       CURRENT_LOAN_PAYMENT_RATE  TOTAL_AMT_ANNUITY  TOTAL_AMT_CREDIT  \\\n",
       "count              307495.000000       2.163040e+05      2.163140e+05   \n",
       "mean                    0.053695       9.411559e+05      1.926691e+06   \n",
       "std                     0.022481       5.921754e+06      2.459518e+06   \n",
       "min                     0.022073       3.006000e+03      4.500000e+04   \n",
       "25%                     0.036900       9.718556e+04      7.524000e+05   \n",
       "50%                     0.050000       3.004183e+05      1.305000e+06   \n",
       "75%                     0.064043       7.142913e+05      2.254457e+06   \n",
       "max                     0.124430       6.802079e+08      3.356847e+08   \n",
       "\n",
       "       TOTAL_EFFORT_RATE  TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "count      216304.000000             216314.000000       216304.000000   \n",
       "mean            5.708165                  0.154313            0.609689   \n",
       "std            33.373152                  0.246091            3.542178   \n",
       "min             0.003830                  0.000603            0.001404   \n",
       "25%             0.640621                  0.072865            0.093214   \n",
       "50%             2.029257                  0.116145            0.211615   \n",
       "75%             4.373481                  0.189675            0.395364   \n",
       "max          3702.839475                 95.097017          264.392053   \n",
       "\n",
       "       DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "count       252133.000000       3.075050e+05  \n",
       "mean             0.156860       9.310608e+04  \n",
       "std              0.133548       1.013739e+05  \n",
       "min             -0.000000       2.812500e+03  \n",
       "25%              0.056098       4.725000e+04  \n",
       "50%              0.118733       7.500000e+04  \n",
       "75%              0.219167       1.125000e+05  \n",
       "max              0.728811       3.900000e+07  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d5d1440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical and categorical columns\n",
    "categorical_cols = [col for col in x.columns if x[col].dtype == 'object']\n",
    "numerical_cols = list(x.drop(categorical_cols, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4507f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df contains 8877 infinite values\n"
     ]
    }
   ],
   "source": [
    "# Checking infinite values\n",
    "  \n",
    "count = np.isinf(x[numerical_cols]).values.sum()\n",
    "print(\"The df contains \" + str(count) + \" infinite values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "66d45e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace inf values by NaN\n",
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec914f7",
   "metadata": {},
   "source": [
    "## II - Split train/test and preprocessing <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "60cf4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5f848ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of preprocessing steps\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('stdscaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3974310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datas\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19248894",
   "metadata": {},
   "source": [
    "## III - Dimensionality reduction <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f888f4",
   "metadata": {},
   "source": [
    "To speed up our algorithms on our model selection, we will reduce the dimensionality of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "95f76a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions x_train before PCA reduction :  (246005, 670)\n",
      "Dimensions x_test before PCA reduction :  (61502, 670)\n",
      "\n",
      "Proceed PCA on train and test set - done in 21s\n",
      "Dimensions x_train after PCA reduction :  (246005, 289)\n",
      "Dimensions x_test after PCA reduction :  (61502, 289)\n"
     ]
    }
   ],
   "source": [
    "# PCA on processed data\n",
    "\n",
    "print(\"Dimensions x_train before PCA reduction : \", x_train_processed.shape)\n",
    "print(\"Dimensions x_test before PCA reduction : \", x_test_processed.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "\n",
    "print(\"\")\n",
    "with timer(\"Proceed PCA on train and test set\"):\n",
    "    x_train_pca = pca.fit_transform(x_train_processed)\n",
    "    x_test_pca = pca.transform(x_test_processed)\n",
    "\n",
    "print(\"Dimensions x_train after PCA reduction : \", x_train_pca.shape)\n",
    "print(\"Dimensions x_test after PCA reduction : \", x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a90f3",
   "metadata": {},
   "source": [
    "## IV - Creation of folds for cv <a class=\"anchor\" id=\"7-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2e115369",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(x_train_pca, y_train, num_folds=num_folds, stratified=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f638ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 45234, 1: 3967})\n",
      "Counter({0: 45234, 1: 3967})\n",
      "Counter({0: 45233, 1: 3968})\n",
      "Counter({0: 45233, 1: 3968})\n",
      "Counter({0: 45233, 1: 3968})\n"
     ]
    }
   ],
   "source": [
    "# Look classs balance in each fold\n",
    "\n",
    "for i in range(5):\n",
    "   print(Counter(y_train.iloc[folds[i][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f302d2",
   "metadata": {},
   "source": [
    "# 4. Baseline model testing <a class=\"anchor\" id=\"8-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683b5ff",
   "metadata": {},
   "source": [
    "## I - Dummy classifiers <a class=\"anchor\" id=\"9-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efdad5",
   "metadata": {},
   "source": [
    "### a. Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e841d3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_frequent</th>\n",
       "      <th>prior</th>\n",
       "      <th>stratified</th>\n",
       "      <th>uniform</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>5.070557</td>\n",
       "      <td>17.256768</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.013446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               most_frequent     prior  stratified    uniform  constant\n",
       "accuracy            0.919981  0.919981    0.853194   0.500376  0.919981\n",
       "f1                  0.000000  0.000000    0.079521   0.136565  0.000000\n",
       "precision           0.000000  0.000000    0.079795   0.079240  0.000000\n",
       "recall              0.000000  0.000000    0.079248   0.493777  0.000000\n",
       "roc_auc             0.500000  0.500000    0.499879   0.500000  0.500000\n",
       "cross_entropy       2.763748  2.763748    5.070557  17.256768  2.763748\n",
       "fit_time            0.016626  0.014415    0.008039   0.012216  0.013446\n",
       "predict_time        0.001482  0.000999    0.001896   0.001412  0.000870"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = test_dummy_classifiers(x_train_pca, y_train, valid_size=0.2, \n",
    "                                 strategies_list=None, random_state=random_state, constant=0, balance_class=False)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9fcc7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.499976\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(dummies.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09341ed1",
   "metadata": {},
   "source": [
    "### b. Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "854ae8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_frequent</th>\n",
       "      <th>prior</th>\n",
       "      <th>stratified</th>\n",
       "      <th>uniform</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.642914</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128392</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079778</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328677</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499461</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>12.333564</td>\n",
       "      <td>17.256768</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               most_frequent     prior  stratified    uniform  constant\n",
       "accuracy            0.919981  0.919981    0.642914   0.500376  0.919981\n",
       "f1                  0.000000  0.000000    0.128392   0.136565  0.000000\n",
       "precision           0.000000  0.000000    0.079778   0.079240  0.000000\n",
       "recall              0.000000  0.000000    0.328677   0.493777  0.000000\n",
       "roc_auc             0.500000  0.500000    0.499461   0.500000  0.500000\n",
       "cross_entropy       2.763748  2.763748   12.333564  17.256768  2.763748\n",
       "fit_time            0.006022  0.001100    0.000928   0.001024  0.001601\n",
       "predict_time        0.001698  0.000466    0.001782   0.000491  0.000528"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_2 = test_dummy_classifiers(x_train_pca, y_train, valid_size=0.2, \n",
    "                                   strategies_list=None, random_state=random_state, constant=0, balance_class=True)\n",
    "dummies_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b186b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.499892\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(dummies_2.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559819",
   "metadata": {},
   "source": [
    "## II - Quick testing <a class=\"anchor\" id=\"10-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef87647",
   "metadata": {},
   "source": [
    "### a. Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ade35fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of some classifiers - done in 22795s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919798</td>\n",
       "      <td>0.915103</td>\n",
       "      <td>0.920063</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.508850</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.662433</td>\n",
       "      <td>0.577950</td>\n",
       "      <td>0.771007</td>\n",
       "      <td>0.767978</td>\n",
       "      <td>0.673001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.770066</td>\n",
       "      <td>2.932232</td>\n",
       "      <td>2.760942</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>422.415992</td>\n",
       "      <td>0.126682</td>\n",
       "      <td>123.843777</td>\n",
       "      <td>0.732317</td>\n",
       "      <td>20675.629150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>1.262353</td>\n",
       "      <td>41.642139</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>743.403910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compute_score_time</th>\n",
       "      <td>0.070560</td>\n",
       "      <td>0.047518</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.045043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RandomForestClassifier  KNeighborsClassifier  \\\n",
       "accuracy                          0.919798              0.915103   \n",
       "f1                                0.000507              0.045693   \n",
       "precision                         0.090909              0.227273   \n",
       "recall                            0.000254              0.025400   \n",
       "roc_auc                           0.662433              0.577950   \n",
       "cross_entropy                     2.770066              2.932232   \n",
       "fit_time                        422.415992              0.126682   \n",
       "predict_time                      1.262353             41.642139   \n",
       "compute_score_time                0.070560              0.047518   \n",
       "\n",
       "                    LogisticRegression  RidgeClassifier           SVC  \n",
       "accuracy                      0.920063         0.919981      0.919981  \n",
       "f1                            0.055249         0.001015      0.000000  \n",
       "precision                     0.508850         0.500000      0.000000  \n",
       "recall                        0.029210         0.000508      0.000000  \n",
       "roc_auc                       0.771007         0.767978      0.673001  \n",
       "cross_entropy                 2.760942         2.763748      2.763748  \n",
       "fit_time                    123.843777         0.732317  20675.629150  \n",
       "predict_time                  0.040803         0.019151    743.403910  \n",
       "compute_score_time            0.046990         0.040441      0.045043  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test some models without hyperparameters optimization\n",
    "\n",
    "models_list = [\n",
    "    # 'GradientBoostingClassifier', \n",
    "    'RandomForestClassifier', \n",
    "    'KNeighborsClassifier',\n",
    "    # 'GaussianProcessClassifier', \n",
    "    'LogisticRegression', \n",
    "    'RidgeClassifier', \n",
    "    # 'SGDClassifier',\n",
    "    # 'LinearSVC', \n",
    "    # 'NuSVC', \n",
    "    'SVC', \n",
    "    # 'DecisionTreeClassifier'\n",
    "]\n",
    "\n",
    "with timer(\"Quick test of some classifiers\"):\n",
    "    quick_test_1 = quick_classifiers_test(x_train_pca, y_train, valid_size=0.2,models_list=models_list, \n",
    "                                          random_state=random_state, max_iter=10000, n_jobs=-1, balance_class=False)\n",
    "\n",
    "quick_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3e18e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.690474\n",
      "Max roc_auc : 0.771007\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(quick_test_1.iloc[4].mean()))\n",
    "print(\"Max roc_auc : {:.6f}\".format(quick_test_1.iloc[4].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981fa71",
   "metadata": {},
   "source": [
    "### b. Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bfdc2cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of some classifiers - done in 1464s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.895043</td>\n",
       "      <td>0.687974</td>\n",
       "      <td>0.841345</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>0.859962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.193629</td>\n",
       "      <td>0.194628</td>\n",
       "      <td>0.310668</td>\n",
       "      <td>0.311547</td>\n",
       "      <td>0.312101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.122645</td>\n",
       "      <td>0.238121</td>\n",
       "      <td>0.244913</td>\n",
       "      <td>0.257115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.471171</td>\n",
       "      <td>0.446787</td>\n",
       "      <td>0.427991</td>\n",
       "      <td>0.397003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.622611</td>\n",
       "      <td>0.770914</td>\n",
       "      <td>0.770269</td>\n",
       "      <td>0.763111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>3.625124</td>\n",
       "      <td>10.777218</td>\n",
       "      <td>5.479852</td>\n",
       "      <td>5.227829</td>\n",
       "      <td>4.836808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>60.890628</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>18.908819</td>\n",
       "      <td>0.173946</td>\n",
       "      <td>584.349935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.926250</td>\n",
       "      <td>11.538366</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>386.572186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compute_score_time</th>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.049717</td>\n",
       "      <td>0.037641</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>0.055558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RandomForestClassifier  KNeighborsClassifier  \\\n",
       "accuracy                          0.895043              0.687974   \n",
       "f1                                0.193629              0.194628   \n",
       "precision                         0.251317              0.122645   \n",
       "recall                            0.157480              0.471171   \n",
       "roc_auc                           0.714894              0.622611   \n",
       "cross_entropy                     3.625124             10.777218   \n",
       "fit_time                         60.890628              0.019599   \n",
       "predict_time                      0.926250             11.538366   \n",
       "compute_score_time                0.036803              0.049717   \n",
       "\n",
       "                    LogisticRegression  RidgeClassifier         SVC  \n",
       "accuracy                      0.841345         0.848641    0.859962  \n",
       "f1                            0.310668         0.311547    0.312101  \n",
       "precision                     0.238121         0.244913    0.257115  \n",
       "recall                        0.446787         0.427991    0.397003  \n",
       "roc_auc                       0.770914         0.770269    0.763111  \n",
       "cross_entropy                 5.479852         5.227829    4.836808  \n",
       "fit_time                     18.908819         0.173946  584.349935  \n",
       "predict_time                  0.018744         0.018717  386.572186  \n",
       "compute_score_time            0.037641         0.041494    0.055558  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with timer(\"Quick test of some classifiers\"):\n",
    "    quick_test_2 = quick_classifiers_test(x_train_pca, y_train, valid_size=0.2,models_list=models_list, \n",
    "                                          random_state=random_state, max_iter=10000, n_jobs=-1, balance_class=True)\n",
    "\n",
    "quick_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1b7d6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.728360\n",
      "Max roc_auc : 0.770914\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(quick_test_2.iloc[4].mean()))\n",
    "print(\"Max roc_auc : {:.6f}\".format(quick_test_2.iloc[4].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1f9d7",
   "metadata": {},
   "source": [
    "Balancing seems to improve our performances, we will apply it on further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f90f3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_class = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b3ade",
   "metadata": {},
   "source": [
    "# 5. Cross-validation model testing <a class=\"anchor\" id=\"11-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb689f",
   "metadata": {},
   "source": [
    "## I - Linear models <a class=\"anchor\" id=\"12-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9935415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 1.0}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 45s\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "64ff2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__alpha': 10}\n",
      "Best score on training set : 0.768\n",
      "Proceed RidgeClassifier - done in 31s\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'alpha' : np.linspace(1, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed RidgeClassifier\"):\n",
    "    RidgeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                           param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea998dd",
   "metadata": {},
   "source": [
    "## II - KNN <a class=\"anchor\" id=\"13-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "458a7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__n_neighbors': 10}\n",
      "Best score on training set : 0.646\n",
      "Proceed KNeighborsClassifier - done in 215s\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed KNeighborsClassifier\"):\n",
    "    KNeighborsClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64066bde",
   "metadata": {},
   "source": [
    "## III - SVM <a class=\"anchor\" id=\"14-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0c37646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LinearSVC - done in 2628s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "\n",
    "model = LinearSVC(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LinearSVC\"):\n",
    "    LinearSVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                     param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "887aa048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 0.4}\n",
      "Best score on training set : 0.685\n",
      "Proceed SVC - done in 3122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "model = SVC(kernel='rbf', random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed SVC\"):\n",
    "    SVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                               param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3021e",
   "metadata": {},
   "source": [
    "## IV - Trees and ensemblist methods <a class=\"anchor\" id=\"15-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "359e2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
      "Best score on training set : 0.575\n",
      "Proceed DecisionTreeClassifier - done in 177s\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "param_grid = {'min_samples_split' : [2, 8], 'min_samples_leaf' : [1, 5]}\n",
    "\n",
    "with timer(\"Proceed DecisionTreeClassifier\"):\n",
    "    DecisionTreeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                  param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b694f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters on training set :\n",
      "{'n_estimators': 500}\n",
      "Best score on training set : 0.760\n",
      "Proceed GradientBoostingClassifier - done in 43891s\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier --> not tested in 2nd iteration (too long to train, 43891s iteration 1)\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state=random_state)\n",
    "# param_grid = {'n_estimators' : [10, 100, 500]}\n",
    "\n",
    "# with timer(\"Proceed GradientBoostingClassifier\"):\n",
    "    # GradientBoostingClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                      # param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b62c007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters on training set :\n",
      "{'model__n_estimators': 500}\n",
      "Best score on training set : 0.729\n",
      "Proceed RandomForestClassifier - done in 1642s\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "param_grid = {'n_estimators' : [10, 500]}\n",
    "\n",
    "with timer(\"Proceed RandomForestClassifier\"):\n",
    "    RandomForestClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                                  param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b34e30",
   "metadata": {},
   "source": [
    "## V - Neural networks <a class=\"anchor\" id=\"16-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "02e2bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test a standard binary classification NN model (activations hidden = relu, last activation = sigmoid) \n",
    "# and try to optimize hyperparameters (learning rate, nb neurons and layers)\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=0.001, input_shape=[289]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0b6a9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "945c8547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 925us/step - loss: 0.2899 - auc: 0.5990\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2634 - auc: 0.7017\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 6s 904us/step - loss: 0.2540 - auc: 0.7344\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2496 - auc: 0.7489\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 6s 899us/step - loss: 0.2471 - auc: 0.7569\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 911us/step - loss: 0.2453 - auc: 0.7625\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 6s 898us/step - loss: 0.2439 - auc: 0.7670\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 898us/step - loss: 0.2427 - auc: 0.7705\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 905us/step - loss: 0.2417 - auc: 0.7734\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 895us/step - loss: 0.2409 - auc: 0.7758\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 894us/step - loss: 0.2895 - auc: 0.6054\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 882us/step - loss: 0.2611 - auc: 0.7067\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 886us/step - loss: 0.2531 - auc: 0.7360\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 887us/step - loss: 0.2493 - auc: 0.7492\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 885us/step - loss: 0.2470 - auc: 0.7567\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 896us/step - loss: 0.2452 - auc: 0.7623\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 881us/step - loss: 0.2439 - auc: 0.7665\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 888us/step - loss: 0.2428 - auc: 0.7697\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2418 - auc: 0.7727\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 887us/step - loss: 0.2409 - auc: 0.7755\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 901us/step - loss: 0.2894 - auc: 0.6072\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2608 - auc: 0.7079\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 6s 902us/step - loss: 0.2530 - auc: 0.7365\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 6s 897us/step - loss: 0.2490 - auc: 0.7502\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 890us/step - loss: 0.2465 - auc: 0.7586\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 906us/step - loss: 0.2448 - auc: 0.7640\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 889us/step - loss: 0.2433 - auc: 0.7684\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 895us/step - loss: 0.2422 - auc: 0.7718\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 903us/step - loss: 0.2412 - auc: 0.7748\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 894us/step - loss: 0.2403 - auc: 0.7775\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 889us/step - loss: 0.2851 - auc: 0.6213\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 878us/step - loss: 0.2599 - auc: 0.7149\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 882us/step - loss: 0.2526 - auc: 0.7403\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 881us/step - loss: 0.2488 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 6s 908us/step - loss: 0.2464 - auc: 0.7594\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 951us/step - loss: 0.2447 - auc: 0.7648\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 6s 912us/step - loss: 0.2433 - auc: 0.7690\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 6s 910us/step - loss: 0.2422 - auc: 0.7722\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 951us/step - loss: 0.2411 - auc: 0.7753\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 1ms/step - loss: 0.2402 - auc: 0.7781\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 872us/step - loss: 0.2871 - auc: 0.6196\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 872us/step - loss: 0.2601 - auc: 0.7141\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 878us/step - loss: 0.2525 - auc: 0.7405\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 880us/step - loss: 0.2489 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 876us/step - loss: 0.2465 - auc: 0.7593\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 6s 902us/step - loss: 0.2449 - auc: 0.7643\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 880us/step - loss: 0.2436 - auc: 0.7683\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 883us/step - loss: 0.2426 - auc: 0.7713\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 6s 950us/step - loss: 0.2417 - auc: 0.7743\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 6s 901us/step - loss: 0.2407 - auc: 0.7769\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 523us/step - loss: 0.4803 - auc: 0.5947\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 524us/step - loss: 0.2962 - auc: 0.7061\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 531us/step - loss: 0.2659 - auc: 0.7399\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 526us/step - loss: 0.2556 - auc: 0.7519\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2508 - auc: 0.7573\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2483 - auc: 0.7609\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 529us/step - loss: 0.2468 - auc: 0.7627\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2458 - auc: 0.7642\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2451 - auc: 0.7654\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2447 - auc: 0.7664\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 526us/step - loss: 0.4809 - auc: 0.5837\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2976 - auc: 0.7011\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2670 - auc: 0.7366\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2564 - auc: 0.7492\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2515 - auc: 0.7555\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2487 - auc: 0.7591\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 516us/step - loss: 0.2471 - auc: 0.7614\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2461 - auc: 0.7633\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2454 - auc: 0.7645\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2449 - auc: 0.7655\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 520us/step - loss: 0.4857 - auc: 0.5701\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 531us/step - loss: 0.2969 - auc: 0.7064\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2662 - auc: 0.7407\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2558 - auc: 0.7521\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2511 - auc: 0.7571\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 530us/step - loss: 0.2486 - auc: 0.7604\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2470 - auc: 0.7625\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2460 - auc: 0.7640\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 527us/step - loss: 0.2453 - auc: 0.7651\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 528us/step - loss: 0.2449 - auc: 0.7659\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 519us/step - loss: 0.4867 - auc: 0.5940\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2970 - auc: 0.7070\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2663 - auc: 0.7411\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2559 - auc: 0.7526\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2512 - auc: 0.7580\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2486 - auc: 0.7614\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2471 - auc: 0.7633\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 523us/step - loss: 0.2461 - auc: 0.7646\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2453 - auc: 0.7658\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2448 - auc: 0.7667\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 516us/step - loss: 0.4858 - auc: 0.5991\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2979 - auc: 0.7065\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 519us/step - loss: 0.2665 - auc: 0.7402\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2559 - auc: 0.7524\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 525us/step - loss: 0.2511 - auc: 0.7579\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 524us/step - loss: 0.2486 - auc: 0.7612\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2470 - auc: 0.7631\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 518us/step - loss: 0.2461 - auc: 0.7642\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2454 - auc: 0.7656\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 505us/step - loss: 0.2449 - auc: 0.7663\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 792us/step - loss: 0.3048 - auc: 0.5652\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2704 - auc: 0.6747\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2601 - auc: 0.7128\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2547 - auc: 0.7312\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2515 - auc: 0.7421\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2494 - auc: 0.7491\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2478 - auc: 0.7543\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2464 - auc: 0.7584\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2454 - auc: 0.7616\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2445 - auc: 0.7645\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 814us/step - loss: 0.2985 - auc: 0.5791\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2684 - auc: 0.6858\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2591 - auc: 0.7179\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2543 - auc: 0.7334\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2513 - auc: 0.7429\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2494 - auc: 0.7492\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2478 - auc: 0.7543\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2466 - auc: 0.7581\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2456 - auc: 0.7612\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2447 - auc: 0.7639\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 824us/step - loss: 0.2917 - auc: 0.6201\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2659 - auc: 0.6954\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2584 - auc: 0.7214\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2541 - auc: 0.7352\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2514 - auc: 0.7439\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2494 - auc: 0.7501\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2480 - auc: 0.7547\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2467 - auc: 0.7586\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2457 - auc: 0.7619\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2448 - auc: 0.7645\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 798us/step - loss: 0.2953 - auc: 0.5856\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2682 - auc: 0.6847\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2591 - auc: 0.7172\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2543 - auc: 0.7334\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2514 - auc: 0.7431\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2494 - auc: 0.7494\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2479 - auc: 0.7542\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2467 - auc: 0.7581\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2457 - auc: 0.7614\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2447 - auc: 0.7642\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 786us/step - loss: 0.3016 - auc: 0.5824\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2702 - auc: 0.6789\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2606 - auc: 0.7133\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2555 - auc: 0.7304\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2523 - auc: 0.7405\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2501 - auc: 0.7475\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2484 - auc: 0.7525\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2470 - auc: 0.7569\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2458 - auc: 0.7604\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2449 - auc: 0.7632\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 707us/step - loss: 0.3044 - auc: 0.5718\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2691 - auc: 0.6715\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2615 - auc: 0.7054\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2571 - auc: 0.7234\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2541 - auc: 0.7345\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2520 - auc: 0.7423\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2503 - auc: 0.7478\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2491 - auc: 0.7518\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2481 - auc: 0.7550\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2472 - auc: 0.7578\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 706us/step - loss: 0.3052 - auc: 0.5819\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2711 - auc: 0.6647\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2637 - auc: 0.6988\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2591 - auc: 0.7185\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2559 - auc: 0.7304\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2535 - auc: 0.7387\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2517 - auc: 0.7445\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2503 - auc: 0.7488\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2492 - auc: 0.7524\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2482 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 696us/step - loss: 0.3561 - auc: 0.5091\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2758 - auc: 0.6151\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2688 - auc: 0.6672\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2639 - auc: 0.6947\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2601 - auc: 0.7129\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2570 - auc: 0.7257\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2546 - auc: 0.7350\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2527 - auc: 0.7419\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2512 - auc: 0.7471\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2500 - auc: 0.7512\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 704us/step - loss: 0.3248 - auc: 0.5735\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2669 - auc: 0.6808\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2598 - auc: 0.7125\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2560 - auc: 0.7281\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2535 - auc: 0.7377\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 749us/step - loss: 0.2517 - auc: 0.7445\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2503 - auc: 0.7493\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2491 - auc: 0.7530\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2481 - auc: 0.7561\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2472 - auc: 0.7588\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 704us/step - loss: 0.3067 - auc: 0.5641\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2724 - auc: 0.6585\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2645 - auc: 0.6940\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2598 - auc: 0.7138\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2567 - auc: 0.7268\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2543 - auc: 0.7358\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2525 - auc: 0.7424\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2511 - auc: 0.7475\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2499 - auc: 0.7514\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2488 - auc: 0.7545\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 792us/step - loss: 0.3142 - auc: 0.5397\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2781 - auc: 0.6420\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2674 - auc: 0.6860\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2610 - auc: 0.7102\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2567 - auc: 0.7255\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2537 - auc: 0.7353\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 799us/step - loss: 0.2516 - auc: 0.7426\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2499 - auc: 0.7478\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 796us/step - loss: 0.2486 - auc: 0.7518\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2475 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 811us/step - loss: 0.3000 - auc: 0.5843\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2729 - auc: 0.6660\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2641 - auc: 0.6998\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2587 - auc: 0.7184\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2552 - auc: 0.7302\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2527 - auc: 0.7384\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2509 - auc: 0.7447\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2495 - auc: 0.7494\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2483 - auc: 0.7531\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2474 - auc: 0.7561\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 798us/step - loss: 0.3004 - auc: 0.5811\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2730 - auc: 0.6661\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2639 - auc: 0.6996\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2587 - auc: 0.7181\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2552 - auc: 0.7299\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2527 - auc: 0.7385\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2509 - auc: 0.7447\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2494 - auc: 0.7493\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2482 - auc: 0.7533\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2472 - auc: 0.7565\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 800us/step - loss: 0.3123 - auc: 0.5734\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2722 - auc: 0.6692\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2631 - auc: 0.7035\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2579 - auc: 0.7221\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2544 - auc: 0.7338\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2520 - auc: 0.7414\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2501 - auc: 0.7475\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2486 - auc: 0.7521\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2475 - auc: 0.7557\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2465 - auc: 0.7589\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 768us/step - loss: 0.3040 - auc: 0.5674\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2761 - auc: 0.6510\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2665 - auc: 0.6900\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2605 - auc: 0.7121\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2565 - auc: 0.7260\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2536 - auc: 0.7358\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2515 - auc: 0.7429\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2499 - auc: 0.7479\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2487 - auc: 0.7521\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2476 - auc: 0.7554\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 764us/step - loss: 0.3311 - auc: 0.5485\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2892 - auc: 0.6091\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2796 - auc: 0.6439\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2734 - auc: 0.6674\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2690 - auc: 0.6842\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2656 - auc: 0.6968\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2629 - auc: 0.7068\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2605 - auc: 0.7149\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2586 - auc: 0.7214\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2570 - auc: 0.7268\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 769us/step - loss: 0.3299 - auc: 0.5374\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2893 - auc: 0.6009\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2796 - auc: 0.6390\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2732 - auc: 0.6644\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2684 - auc: 0.6829\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2648 - auc: 0.6966\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2619 - auc: 0.7072\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2596 - auc: 0.7156\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2577 - auc: 0.7222\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2561 - auc: 0.7277\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 765us/step - loss: 0.3260 - auc: 0.5403\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2915 - auc: 0.5932\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2827 - auc: 0.6263\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2768 - auc: 0.6499\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2723 - auc: 0.6673\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2687 - auc: 0.6812\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2657 - auc: 0.6923\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2632 - auc: 0.7014\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2612 - auc: 0.7092\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2594 - auc: 0.7157\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 760us/step - loss: 0.3294 - auc: 0.5622\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2850 - auc: 0.6209\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2766 - auc: 0.6517\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2713 - auc: 0.6724\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 762us/step - loss: 0.2674 - auc: 0.6874\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2644 - auc: 0.6987\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2619 - auc: 0.7076\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2599 - auc: 0.7148\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2582 - auc: 0.7209\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2567 - auc: 0.7256\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 763us/step - loss: 0.3239 - auc: 0.5082\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2939 - auc: 0.5848\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2835 - auc: 0.6283\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2766 - auc: 0.6561\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2715 - auc: 0.6756\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2676 - auc: 0.6904\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2645 - auc: 0.7012\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2619 - auc: 0.7100\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2598 - auc: 0.7170\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2580 - auc: 0.7230\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 813us/step - loss: 0.2573 - auc: 0.7258\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2441 - auc: 0.7669\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2407 - auc: 0.7771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2384 - auc: 0.7841\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2364 - auc: 0.7895\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2350 - auc: 0.7937\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2331 - auc: 0.7986\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2316 - auc: 0.8027\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2299 - auc: 0.8064\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2279 - auc: 0.8112\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 828us/step - loss: 0.2590 - auc: 0.7213\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2445 - auc: 0.7656\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2407 - auc: 0.7767\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 823us/step - loss: 0.2385 - auc: 0.7827\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2368 - auc: 0.7880\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2348 - auc: 0.7928\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 829us/step - loss: 0.2331 - auc: 0.7975\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2311 - auc: 0.8027\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2295 - auc: 0.8067\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 828us/step - loss: 0.2279 - auc: 0.8109\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 816us/step - loss: 0.2591 - auc: 0.7191\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2445 - auc: 0.7659\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2409 - auc: 0.7766\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 813us/step - loss: 0.2384 - auc: 0.7835\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2363 - auc: 0.7895\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 870us/step - loss: 0.2346 - auc: 0.7943\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 838us/step - loss: 0.2330 - auc: 0.7987\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 837us/step - loss: 0.2310 - auc: 0.8038\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2295 - auc: 0.8078\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2278 - auc: 0.8122\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 814us/step - loss: 0.2571 - auc: 0.7257\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2442 - auc: 0.7675\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2406 - auc: 0.7775\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2387 - auc: 0.7836\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2364 - auc: 0.7893\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2346 - auc: 0.7942\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2331 - auc: 0.7984\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2315 - auc: 0.8029\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2300 - auc: 0.8064\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2283 - auc: 0.8107\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 820us/step - loss: 0.2590 - auc: 0.7205\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2444 - auc: 0.7661\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2411 - auc: 0.7762\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2387 - auc: 0.7831\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2367 - auc: 0.7886\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2349 - auc: 0.7938\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 826us/step - loss: 0.2333 - auc: 0.7977\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2315 - auc: 0.8022\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2300 - auc: 0.8062\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2285 - auc: 0.8104\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 779us/step - loss: 0.3123 - auc: 0.5608\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2785 - auc: 0.6457\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2683 - auc: 0.6837\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2620 - auc: 0.7065\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2578 - auc: 0.7214\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2546 - auc: 0.7320\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2522 - auc: 0.7399\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2504 - auc: 0.7459\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2488 - auc: 0.7505\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2477 - auc: 0.7543\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 769us/step - loss: 0.3062 - auc: 0.5695\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2741 - auc: 0.6653\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2650 - auc: 0.6984\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2595 - auc: 0.7166\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2559 - auc: 0.7291\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2534 - auc: 0.7376\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2515 - auc: 0.7439\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2501 - auc: 0.7485\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2489 - auc: 0.7521\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 818us/step - loss: 0.2479 - auc: 0.7553\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 777us/step - loss: 0.3100 - auc: 0.5476\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2803 - auc: 0.6379\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 767us/step - loss: 0.2691 - auc: 0.6807\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2623 - auc: 0.7058\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2578 - auc: 0.7213\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2547 - auc: 0.7318\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2525 - auc: 0.7395\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2508 - auc: 0.7449\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2494 - auc: 0.7492\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2482 - auc: 0.7529\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 775us/step - loss: 0.3073 - auc: 0.5546\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2761 - auc: 0.6517\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2665 - auc: 0.6907\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2608 - auc: 0.7121\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2570 - auc: 0.7257\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2543 - auc: 0.7346\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2522 - auc: 0.7415\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2506 - auc: 0.7466\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2494 - auc: 0.7506\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2483 - auc: 0.7540\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 797us/step - loss: 0.2990 - auc: 0.5905\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2763 - auc: 0.6581\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2674 - auc: 0.6901\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2618 - auc: 0.7091\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2580 - auc: 0.7219\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2552 - auc: 0.7314\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2531 - auc: 0.7380\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2514 - auc: 0.7436\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2499 - auc: 0.7478\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2488 - auc: 0.7517\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 707us/step - loss: 0.3086 - auc: 0.5781\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2640 - auc: 0.6923\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2555 - auc: 0.7278\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2512 - auc: 0.7434\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2487 - auc: 0.7514\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2472 - auc: 0.7564\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2461 - auc: 0.7604\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2452 - auc: 0.7629\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2445 - auc: 0.7653\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2439 - auc: 0.7670\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 9s 701us/step - loss: 0.3051 - auc: 0.5948\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2634 - auc: 0.6974\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2565 - auc: 0.7264\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2525 - auc: 0.7412\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2498 - auc: 0.7499\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 714us/step - loss: 0.2481 - auc: 0.7554\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2467 - auc: 0.7597\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2457 - auc: 0.7628\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 723us/step - loss: 0.2449 - auc: 0.7655\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2441 - auc: 0.7675\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 720us/step - loss: 0.2909 - auc: 0.6060\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2640 - auc: 0.6983\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2576 - auc: 0.7250\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2542 - auc: 0.7378\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 715us/step - loss: 0.2519 - auc: 0.7462\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2503 - auc: 0.7518\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2492 - auc: 0.7558\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2482 - auc: 0.7588\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2472 - auc: 0.7618\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 711us/step - loss: 0.2465 - auc: 0.7638\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 695us/step - loss: 0.2937 - auc: 0.6031\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2636 - auc: 0.6971\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2576 - auc: 0.7238\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2542 - auc: 0.7377\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2519 - auc: 0.7461\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2502 - auc: 0.7519\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 714us/step - loss: 0.2489 - auc: 0.7560\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2477 - auc: 0.7594\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2467 - auc: 0.7623\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2459 - auc: 0.7644\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 8s 686us/step - loss: 0.2911 - auc: 0.6029\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 693us/step - loss: 0.2635 - auc: 0.6973\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2568 - auc: 0.7258\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2531 - auc: 0.7399\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2507 - auc: 0.7480\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2491 - auc: 0.7533\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 719us/step - loss: 0.2478 - auc: 0.7573\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2467 - auc: 0.7604\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2458 - auc: 0.7630\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2451 - auc: 0.7652\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 815us/step - loss: 0.3088 - auc: 0.5516\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2824 - auc: 0.6219\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2740 - auc: 0.6581\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2683 - auc: 0.6815\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 828us/step - loss: 0.2639 - auc: 0.6988\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2605 - auc: 0.7118\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2577 - auc: 0.7222\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 835us/step - loss: 0.2554 - auc: 0.7303\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2536 - auc: 0.7365\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2520 - auc: 0.7415\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 10s 812us/step - loss: 0.3195 - auc: 0.5226\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2836 - auc: 0.6087\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2736 - auc: 0.6549\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2671 - auc: 0.6832\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2623 - auc: 0.7028\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2587 - auc: 0.7165\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2559 - auc: 0.7269\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2538 - auc: 0.7342\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 822us/step - loss: 0.2521 - auc: 0.7404\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2507 - auc: 0.7452\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 815us/step - loss: 0.3063 - auc: 0.5532\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2781 - auc: 0.6401\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2696 - auc: 0.6771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2643 - auc: 0.6976\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2606 - auc: 0.7116\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2578 - auc: 0.7218\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 830us/step - loss: 0.2556 - auc: 0.7294\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2539 - auc: 0.7354\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2524 - auc: 0.7405\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 816us/step - loss: 0.2512 - auc: 0.7444\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 812us/step - loss: 0.3136 - auc: 0.5384\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2787 - auc: 0.6357\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 808us/step - loss: 0.2691 - auc: 0.6774\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2633 - auc: 0.7007\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 819us/step - loss: 0.2592 - auc: 0.7158\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2563 - auc: 0.7263\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2541 - auc: 0.7340\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2523 - auc: 0.7401\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2509 - auc: 0.7450\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 807us/step - loss: 0.2497 - auc: 0.7490\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 9s 809us/step - loss: 0.3076 - auc: 0.5508\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2796 - auc: 0.6383\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2701 - auc: 0.6771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 805us/step - loss: 0.2641 - auc: 0.6991\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2599 - auc: 0.7137\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2568 - auc: 0.7243\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2544 - auc: 0.7320\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 799us/step - loss: 0.2526 - auc: 0.7384\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2511 - auc: 0.7431\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2500 - auc: 0.7469\n",
      "Epoch 1/10\n",
      "7688/7688 [==============================] - 8s 509us/step - loss: 0.4499 - auc: 0.6176\n",
      "Epoch 2/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2818 - auc: 0.7227\n",
      "Epoch 3/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2587 - auc: 0.7473\n",
      "Epoch 4/10\n",
      "7688/7688 [==============================] - 4s 507us/step - loss: 0.2514 - auc: 0.7560\n",
      "Epoch 5/10\n",
      "7688/7688 [==============================] - 4s 510us/step - loss: 0.2483 - auc: 0.7600\n",
      "Epoch 6/10\n",
      "7688/7688 [==============================] - 4s 507us/step - loss: 0.2466 - auc: 0.7627\n",
      "Epoch 7/10\n",
      "7688/7688 [==============================] - 4s 505us/step - loss: 0.2456 - auc: 0.7642\n",
      "Epoch 8/10\n",
      "7688/7688 [==============================] - 4s 509us/step - loss: 0.2450 - auc: 0.7655\n",
      "Epoch 9/10\n",
      "7688/7688 [==============================] - 4s 541us/step - loss: 0.2446 - auc: 0.7662\n",
      "Epoch 10/10\n",
      "7688/7688 [==============================] - 4s 503us/step - loss: 0.2442 - auc: 0.7671\n",
      "Proceed NeuralNetwork - done in 2813s\n"
     ]
    }
   ],
   "source": [
    "# Testing hyperparameters\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.linspace(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "# Testing model parameters\n",
    "nn_clf = RandomizedSearchCV(keras_clf, param_distribs, n_iter=10, \n",
    "                            cv=folds, scoring=optimized_metric, random_state=random_state)\n",
    "\n",
    "with timer(\"Proceed NeuralNetwork\"):\n",
    "    nn_clf.fit(x_train_pca, y_train, epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c661b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters on training set :\n",
      "{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}\n",
      "Best score on training set : 0.764\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters on training set :\")\n",
    "print(nn_clf.best_params_)\n",
    "print(\"Best score on training set : {:.3f}\".format(nn_clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636224ce",
   "metadata": {},
   "source": [
    "## VI - Compare <a class=\"anchor\" id=\"17-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6119db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores in this iteration\n",
    "\n",
    "cv_clfs = {\n",
    "    'LogisticRegression' : LogisticRegression_clf,\n",
    "    'RidgeClassifier' : RidgeClassifier_clf,\n",
    "    'KNeighborsClassifier' : KNeighborsClassifier_clf,\n",
    "    'LinearSVC' : LinearSVC_clf,\n",
    "    'SVC' : SVC_clf,\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier_clf,\n",
    "    # 'GradientBoostingClassifier' : GradientBoostingClassifier_clf,\n",
    "    'RandomForestClassifier' : RandomForestClassifier_clf,\n",
    "    'NeuralNetwork' : nn_clf,\n",
    "}\n",
    "\n",
    "iteration_2 = pd.DataFrame()\n",
    "\n",
    "for key, clf in cv_clfs.items():\n",
    "    iteration_2[key] = [clf.best_score_, clf.best_params_]\n",
    "    \n",
    "iteration_2.index = ['best_score_ : ' + optimized_metric, 'best_params_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "577ec36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>SVC</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>NeuralNetwork</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score_ : roc_auc</th>\n",
       "      <td>0.768028</td>\n",
       "      <td>0.767798</td>\n",
       "      <td>0.645989</td>\n",
       "      <td>0.768115</td>\n",
       "      <td>0.685251</td>\n",
       "      <td>0.575201</td>\n",
       "      <td>0.728944</td>\n",
       "      <td>0.763832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params_</th>\n",
       "      <td>{'model__C': 1.0}</td>\n",
       "      <td>{'model__alpha': 10}</td>\n",
       "      <td>{'model__n_neighbors': 10}</td>\n",
       "      <td>{'model__C': 0.1}</td>\n",
       "      <td>{'model__C': 0.4}</td>\n",
       "      <td>{'model__min_samples_leaf': 5, 'model__min_samples_split': 2}</td>\n",
       "      <td>{'model__n_estimators': 500}</td>\n",
       "      <td>{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LogisticRegression       RidgeClassifier  \\\n",
       "best_score_ : roc_auc           0.768028              0.767798   \n",
       "best_params_           {'model__C': 1.0}  {'model__alpha': 10}   \n",
       "\n",
       "                             KNeighborsClassifier          LinearSVC  \\\n",
       "best_score_ : roc_auc                    0.645989           0.768115   \n",
       "best_params_           {'model__n_neighbors': 10}  {'model__C': 0.1}   \n",
       "\n",
       "                                     SVC  \\\n",
       "best_score_ : roc_auc           0.685251   \n",
       "best_params_           {'model__C': 0.4}   \n",
       "\n",
       "                                                              DecisionTreeClassifier  \\\n",
       "best_score_ : roc_auc                                                       0.575201   \n",
       "best_params_           {'model__min_samples_leaf': 5, 'model__min_samples_split': 2}   \n",
       "\n",
       "                             RandomForestClassifier  \\\n",
       "best_score_ : roc_auc                      0.728944   \n",
       "best_params_           {'model__n_estimators': 500}   \n",
       "\n",
       "                                                                                                  NeuralNetwork  \n",
       "best_score_ : roc_auc                                                                                  0.763832  \n",
       "best_params_           {'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f7559dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC                 0.768115\n",
       "LogisticRegression        0.768028\n",
       "RidgeClassifier           0.767798\n",
       "NeuralNetwork             0.763832\n",
       "RandomForestClassifier    0.728944\n",
       "SVC                       0.685251\n",
       "KNeighborsClassifier      0.645989\n",
       "DecisionTreeClassifier    0.575201\n",
       "Name: best_score_ : roc_auc, dtype: object"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_2.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2a21dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_2.to_csv('./Scores/iteration_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc770036",
   "metadata": {},
   "source": [
    "Logistic regression has almost the best performance and is much faster to train than LinearSVC so we will choose this algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d530d2",
   "metadata": {},
   "source": [
    "# 6. Selected model fine tuning and interpretation <a class=\"anchor\" id=\"18-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438c30c",
   "metadata": {},
   "source": [
    "## I - Fine tuning <a class=\"anchor\" id=\"19-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2512e",
   "metadata": {},
   "source": [
    "### a. With lbfgs solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a718b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 2.3000000000000003, 'model__class_weight': None}\n",
      "Best score on training set : 0.769\n",
      "Proceed LogisticRegression - done in 248s\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : same test as model selection with more parameters\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='l2', solver='lbfgs')\n",
    "param_grid = {\n",
    "    'C' : np.linspace(0.1, 10, num=10),\n",
    "    'class_weight' : [None, 'balanced']\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_1 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e7cf5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 1.9444444444444444}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 122s\n"
     ]
    }
   ],
   "source": [
    "# Test 2 : we keep class_weight=None and test other values of C centered in our result\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='l2', solver='lbfgs', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(1.5, 3.5, num=10),\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_2 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd027b",
   "metadata": {},
   "source": [
    "### b. With saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "ed6262a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 4.0, 'model__l1_ratio': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 20467s\n"
     ]
    }
   ],
   "source": [
    "# Test 3 : solver saga with different penalties ratios \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='elasticnet', solver='saga', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(1, 5, num=5),\n",
    "    'l1_ratio' : np.linspace(0, 1, num=11)\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_3 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2d38458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 4.5, 'model__l1_ratio': 0.1}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 4418s\n"
     ]
    }
   ],
   "source": [
    "# Test 4 : centered search on previous results\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', penalty='elasticnet', solver='saga', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(3.5, 4.5, num=3),\n",
    "    'l1_ratio' : np.linspace(0.05, 0.15, num=3)\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_4 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5ebb3",
   "metadata": {},
   "source": [
    "### c. With liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1a30b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 3.4000000000000004, 'model__penalty': 'l2'}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 716s\n"
     ]
    }
   ],
   "source": [
    "# Test 5 : solver liblinear with l1 and l2 penalties \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', solver='liblinear', class_weight=None)\n",
    "param_grid = {\n",
    "    'C' : np.linspace(0.1, 10, num=10),\n",
    "    'penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_5 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b6190644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 3.5}\n",
      "Best score on training set : 0.768\n",
      "Proceed LogisticRegression - done in 141s\n"
     ]
    }
   ],
   "source": [
    "# Test 6 : centered search on previous results \n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', solver='liblinear', class_weight=None, penalty='l2')\n",
    "param_grid = {\n",
    "    'C' : np.linspace(2.5, 4.5, num=5),\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_6 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, optimized_metric, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30492ae",
   "metadata": {},
   "source": [
    "### d. Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "08c824a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores in this iteration\n",
    "\n",
    "models = [LogisticRegression_clf_1, LogisticRegression_clf_2, LogisticRegression_clf_3,\n",
    "LogisticRegression_clf_4, LogisticRegression_clf_5, LogisticRegression_clf_6]\n",
    "\n",
    "fine_tuning = pd.DataFrame()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    fine_tuning['LogisticRegression_clf_{}'.format(i+1)] = [model.best_score_, model.best_params_]\n",
    "    \n",
    "fine_tuning.index = ['best_score_ : ' + optimized_metric, 'best_params_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a5cc44ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_clf_1    0.768558\n",
       "LogisticRegression_clf_3    0.768387\n",
       "LogisticRegression_clf_5     0.76834\n",
       "LogisticRegression_clf_2    0.768197\n",
       "LogisticRegression_clf_6    0.768014\n",
       "LogisticRegression_clf_4    0.767996\n",
       "Name: best_score_ : roc_auc, dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea856654",
   "metadata": {},
   "source": [
    "## II - Business optimization <a class=\"anchor\" id=\"20-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580f010",
   "metadata": {},
   "source": [
    "The choice of our algorithm has been made based on the technical metric of roc auc, we will now try to look the results of this algorithm based on a business point of view. For this we will keep in mind that a type II error will have a biggest impact than a type I (taking the risk of a customer not repaying a loan is worst than not giving a loan to a customer who would has been able to repay). We will optimize paramaters according to this, notably by modifying the threshold of our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a456ea3f",
   "metadata": {},
   "source": [
    "### a. Assess current performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1ee2d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model - done in 13s\n"
     ]
    }
   ],
   "source": [
    "# Best model training\n",
    "\n",
    "best_C = LogisticRegression_clf_1.best_params_['model__C']\n",
    "\n",
    "final_model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                                 multi_class='ovr', penalty='l2', solver='lbfgs',\n",
    "                                class_weight=None, C = best_C)\n",
    "\n",
    "# Balance class pipeline\n",
    "over = imblearn.over_sampling.SMOTE(sampling_strategy=0.1)\n",
    "under = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under), ('model', final_model)]\n",
    "pipe = imblearn.pipeline.Pipeline(steps=steps)\n",
    "\n",
    "with timer(\"Train model\"):\n",
    "    pipe.fit(x_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "564e5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc on train set : 0.772129\n",
      "roc auc on test set : 0.765188\n"
     ]
    }
   ],
   "source": [
    "# Look score on test and train set\n",
    "\n",
    "probas_train = pipe.predict_proba(x_train_pca)[:,1]\n",
    "probas_test = pipe.predict_proba(x_test_pca)[:,1]\n",
    "\n",
    "roc_auc_train = roc_auc_score(y_train, probas_train)\n",
    "roc_auc_test = roc_auc_score(y_test, probas_test)\n",
    "\n",
    "print(\"roc auc on train set : {:.6f}\".format(roc_auc_train))\n",
    "print(\"roc auc on test set : {:.6f}\".format(roc_auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "1b6f3093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking confusion matrix\n",
    "\n",
    "predictions = pipe.predict(x_train_pca)\n",
    "cm = confusion_matrix(y_train, predictions, labels=pipe.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipe.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52842532",
   "metadata": {},
   "source": [
    "We can see that our model predicts more false negatives than true positives, which is clearly not ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5ae27d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.84\n",
      "F1 : 0.32\n",
      "Precision : 0.24\n",
      "Recall : 0.45\n"
     ]
    }
   ],
   "source": [
    "# Compute some scores\n",
    "\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "f1 = f1_score(y_train, predictions)\n",
    "precision = precision_score(y_train, predictions)\n",
    "recall = recall_score(y_train, predictions)\n",
    "\n",
    "print(\"Accuracy : {:.2f}\".format(accuracy))\n",
    "print(\"F1 : {:.2f}\".format(f1))\n",
    "print(\"Precision : {:.2f}\".format(precision))\n",
    "print(\"Recall : {:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05aaf6",
   "metadata": {},
   "source": [
    "We will try to increase the recall (detecting the more positive customers possible), thus we need to keep a good accuracy and precision. We will use a metric adapted to our problematic : \n",
    "- both false negatives et false positives has a cost for the bank\n",
    "- a false negative has a high cost because loan won't be repayed\n",
    "- a false positive has a lower cost but still represents an opportunity cost with the loss of a potential good customer\n",
    "- the F1 score allows to optimize both precision and recall with the same weight\n",
    "- we want to give more weight to false negatives, the fbeta_score allows us to do this by setting beta>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8e20d232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fbeta : 0.39\n"
     ]
    }
   ],
   "source": [
    "fbeta = fbeta_score(y_train, predictions, beta=2)\n",
    "print(\"Fbeta : {:.2f}\".format(fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f45a17",
   "metadata": {},
   "source": [
    "### b. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "40c19ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scorer for gridsearch\n",
    "scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b95a403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best parameters on training set :\n",
      "{'model__C': 1.0}\n",
      "Best score on training set : 0.383\n",
      "Proceed LogisticRegression - done in 835s\n"
     ]
    }
   ],
   "source": [
    "# Optmize parameters\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000, \n",
    "                           multi_class='ovr', solver='liblinear', class_weight=None, penalty='l2')\n",
    "param_grid = {\n",
    "    'C' : np.linspace(1, 5, num=10),\n",
    "}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf_7 = run_GridSearchCV(model, x_train_pca, y_train, folds, \n",
    "                                              param_grid, scorer, balance_class=balance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f29c503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.40</th>\n",
       "      <th>0.45</th>\n",
       "      <th>0.50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fbeta</th>\n",
       "      <td>0.314240</td>\n",
       "      <td>0.340586</td>\n",
       "      <td>0.371139</td>\n",
       "      <td>0.398132</td>\n",
       "      <td>0.417916</td>\n",
       "      <td>0.431221</td>\n",
       "      <td>0.436710</td>\n",
       "      <td>0.429817</td>\n",
       "      <td>0.413524</td>\n",
       "      <td>0.385699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.126599</td>\n",
       "      <td>0.246515</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>0.490169</td>\n",
       "      <td>0.583817</td>\n",
       "      <td>0.660462</td>\n",
       "      <td>0.723262</td>\n",
       "      <td>0.773407</td>\n",
       "      <td>0.813301</td>\n",
       "      <td>0.844036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.084118</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.124562</td>\n",
       "      <td>0.141237</td>\n",
       "      <td>0.159434</td>\n",
       "      <td>0.179449</td>\n",
       "      <td>0.199967</td>\n",
       "      <td>0.222371</td>\n",
       "      <td>0.245369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.973435</td>\n",
       "      <td>0.936233</td>\n",
       "      <td>0.882902</td>\n",
       "      <td>0.819034</td>\n",
       "      <td>0.751487</td>\n",
       "      <td>0.680663</td>\n",
       "      <td>0.603135</td>\n",
       "      <td>0.526716</td>\n",
       "      <td>0.450045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0.05      0.10      0.15      0.20      0.25      0.30  \\\n",
       "fbeta      0.314240  0.340586  0.371139  0.398132  0.417916  0.431221   \n",
       "accuracy   0.126599  0.246515  0.375801  0.490169  0.583817  0.660462   \n",
       "precision  0.084118  0.094595  0.108700  0.124562  0.141237  0.159434   \n",
       "recall     0.994203  0.973435  0.936233  0.882902  0.819034  0.751487   \n",
       "\n",
       "               0.35      0.40      0.45      0.50  \n",
       "fbeta      0.436710  0.429817  0.413524  0.385699  \n",
       "accuracy   0.723262  0.773407  0.813301  0.844036  \n",
       "precision  0.179449  0.199967  0.222371  0.245369  \n",
       "recall     0.680663  0.603135  0.526716  0.450045  "
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize prediction threshold\n",
    "\n",
    "test_classification_thresholds(LogisticRegression_clf_7, x_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf024a4",
   "metadata": {},
   "source": [
    "The fbeta score is maximized at a threshold of 0.35 for prediction. Compared to our previous recall, the accuracy is 12 pts lower but the recall is 23 pts higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c81af8",
   "metadata": {},
   "source": [
    "## III - Features importance <a class=\"anchor\" id=\"21-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be7513",
   "metadata": {},
   "source": [
    "Valeurs testées première itération (cleaned_data_1):\n",
    "- LogisticRegression : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.1 -> tester plus petit\n",
    "- RidgeClassifier : {'alpha' : np.linspace(1, 10, num=4, dtype=int)}, best : alpha = 10 -> tester plus grand\n",
    "- KNeighborsClassifier : {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}, best : n_neighbors = 10 > tester plus grand\n",
    "- LinearSVC : {'penalty' : ['l1', 'l2'], 'C' : np.linspace(0.1, 1, num=4)}, bests :\n",
    "    - C = 0.7 --> tester valeurs autour\n",
    "    - penalty = l2 --> conserver\n",
    "- SVC : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.4 -> tester valeurs autour\n",
    "- DecisionTreeClassifier : {'min_samples_split' : [2, 4, 8], 'min_samples_leaf' : [1, 3, 5]}, bests :\n",
    "    - min_samples_split = 2 --> conserver\n",
    "    - min_samples_leaf = 5 --> tester plus grand\n",
    "- GradientBoostingClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand\n",
    "- RandomForestClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
