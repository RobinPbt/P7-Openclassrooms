{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cb37a03",
   "metadata": {},
   "source": [
    "# Table of Contents --> TBU\n",
    "\n",
    "1. [Global parameters](#1-bullet) <br>\n",
    "    <br>\n",
    "    \n",
    "2. [Loading datas](#2-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "3. [Preprocessing](#3-bullet) <br>\n",
    "    I - [Cleaning](#4-bullet) <br>\n",
    "    II - [Split train/test and preprocessing](#5-bullet) <br>\n",
    "    III - [Dimensionality reduction](#6-bullet) <br>\n",
    "    IV - [Creation of folds for cv](#7-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "4. [Model testing](#8-bullet) <br>\n",
    "    I - [Dummy classifiers ](#9-bullet) <br>\n",
    "    II - [Quick testing](#15-bullet) <br>\n",
    "    III - [Linear models](#10-bullet) <br>\n",
    "    VI - [KNN](#11-bullet) <br>\n",
    "    V - [SVM](#12-bullet) <br>\n",
    "    VI - [Trees and ensemblist methods](#13-bullet) <br>\n",
    "    VII - [Neural networks](#14-bullet) <br>\n",
    "    VIII - [Compare](#16-bullet) <br>\n",
    "    <br>\n",
    "\n",
    "5. [xx](#xx-bullet) <br>\n",
    "    I - [xx](#xx-bullet) <br>\n",
    "    II - [xx](#xx-bullet) <br>\n",
    "    III - [xx](#xx-bullet) <br>\n",
    "    IV - [xx](#xx-bullet) <br>\n",
    "    V - [xx](#xx-bullet) <br>\n",
    "    VI - [xx](#xx-bullet) <br>\n",
    "    VII - [xx](#xx-bullet) <br>\n",
    "    <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702077a",
   "metadata": {},
   "source": [
    "# 1. Global parameters <a class=\"anchor\" id=\"1-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "40275ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General input\n",
    "random_state = 50 \n",
    "\n",
    "# Cross-validation\n",
    "optimized_metric = 'roc_auc' \n",
    "num_folds = 5\n",
    "stratified = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c16c80",
   "metadata": {},
   "source": [
    "# 2. Loading datas <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a30bce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import timeit\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "# warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "# Project specific functions\n",
    "from P7_functions import *\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import manifold, decomposition\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e839d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "74f2bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_csv('./Clean_datas/baseline_data.csv', sep=\",\")\n",
    "data = pd.read_csv('./Clean_datas/clean_data_1.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "32fb710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.158397</td>\n",
       "      <td>0.498036</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>247829.081500</td>\n",
       "      <td>888586.065</td>\n",
       "      <td>1.223847</td>\n",
       "      <td>0.227890</td>\n",
       "      <td>0.278903</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>202500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145199</td>\n",
       "      <td>0.208736</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>292122.185803</td>\n",
       "      <td>2103502.500</td>\n",
       "      <td>1.081934</td>\n",
       "      <td>0.128357</td>\n",
       "      <td>0.138874</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052803</td>\n",
       "      <td>0.431748</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159905</td>\n",
       "      <td>67500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>121500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0      100002       1         Cash loans           M            N   \n",
       "1           1      100003       0         Cash loans           F            N   \n",
       "2           2      100004       0    Revolving loans           M            Y   \n",
       "3           3      100006       0         Cash loans           F            N   \n",
       "4           4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  ...  \\\n",
       "0               Y             0          202500.0    406597.5  ...   \n",
       "1               N             0          270000.0   1293502.5  ...   \n",
       "2               Y             0           67500.0    135000.0  ...   \n",
       "3               Y             0          135000.0    312682.5  ...   \n",
       "4               Y             0          121500.0    513000.0  ...   \n",
       "\n",
       "   CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "0          1.158397                         0.498036   \n",
       "1          1.145199                         0.208736   \n",
       "2          1.000000                         0.500000   \n",
       "3          1.052803                         0.431748   \n",
       "4          1.000000                         0.236842   \n",
       "\n",
       "  CURRENT_LOAN_PAYMENT_RATE TOTAL_AMT_ANNUITY TOTAL_AMT_CREDIT  \\\n",
       "0                  0.060749     247829.081500       888586.065   \n",
       "1                  0.027598     292122.185803      2103502.500   \n",
       "2                  0.050000               NaN              NaN   \n",
       "3                  0.094941               NaN              NaN   \n",
       "4                  0.042623               NaN              NaN   \n",
       "\n",
       "  TOTAL_EFFORT_RATE TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "0          1.223847                 0.227890            0.278903   \n",
       "1          1.081934                 0.128357            0.138874   \n",
       "2               NaN                      NaN                 NaN   \n",
       "3               NaN                      NaN                 NaN   \n",
       "4               NaN                      NaN                 NaN   \n",
       "\n",
       "   DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "0            0.067329           202500.0  \n",
       "1            0.070862           135000.0  \n",
       "2            0.011814            67500.0  \n",
       "3            0.159905            67500.0  \n",
       "4            0.152418           121500.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e16ce3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0', 'SK_ID_CURR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c44e65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET']\n",
    "x = data.drop(['TARGET'], axis=1)\n",
    "baseline_y = baseline_data['TARGET']\n",
    "baseline_x = baseline_data.drop(['TARGET'], axis=1) # Note : categorical data already encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5b893e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307507, 399)\n",
      "(307507,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b4fa2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91927\n",
       "1    0.08073\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look targets breakdown\n",
    "y.value_counts().apply(lambda x: x / y.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939e334",
   "metadata": {},
   "source": [
    "We have very imbalanced classes, we will use StratifiedKFold for now. And see for SMOTE after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2557b7",
   "metadata": {},
   "source": [
    "# 3. Preprocessing <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783be02",
   "metadata": {},
   "source": [
    "## I - Cleaning <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "50247db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_LOAN_LTV</th>\n",
       "      <th>CURRENT_LOAN_INCOME_CREDIT_PERC</th>\n",
       "      <th>CURRENT_LOAN_PAYMENT_RATE</th>\n",
       "      <th>TOTAL_AMT_ANNUITY</th>\n",
       "      <th>TOTAL_AMT_CREDIT</th>\n",
       "      <th>TOTAL_EFFORT_RATE</th>\n",
       "      <th>TOTAL_INCOME_CREDIT_PERC</th>\n",
       "      <th>TOTAL_PAYMENT_RATE</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307507.000000</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>3.075070e+05</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>3.072290e+05</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>307229.000000</td>\n",
       "      <td>307507.000000</td>\n",
       "      <td>307495.000000</td>\n",
       "      <td>2.163040e+05</td>\n",
       "      <td>2.163140e+05</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>216314.000000</td>\n",
       "      <td>216304.000000</td>\n",
       "      <td>252133.000000</td>\n",
       "      <td>3.075050e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.417047</td>\n",
       "      <td>1.687977e+05</td>\n",
       "      <td>5.990286e+05</td>\n",
       "      <td>27108.666786</td>\n",
       "      <td>5.383977e+05</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-16037.027271</td>\n",
       "      <td>-2384.142254</td>\n",
       "      <td>-4986.131376</td>\n",
       "      <td>-2994.201670</td>\n",
       "      <td>...</td>\n",
       "      <td>1.122994</td>\n",
       "      <td>0.399669</td>\n",
       "      <td>0.053695</td>\n",
       "      <td>9.411559e+05</td>\n",
       "      <td>1.926691e+06</td>\n",
       "      <td>5.708165</td>\n",
       "      <td>0.154313</td>\n",
       "      <td>0.609689</td>\n",
       "      <td>0.156860</td>\n",
       "      <td>9.310608e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.722119</td>\n",
       "      <td>2.371246e+05</td>\n",
       "      <td>4.024926e+05</td>\n",
       "      <td>14493.798379</td>\n",
       "      <td>3.694472e+05</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>4363.982424</td>\n",
       "      <td>2338.327666</td>\n",
       "      <td>3522.883030</td>\n",
       "      <td>1509.454566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124036</td>\n",
       "      <td>0.507927</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>5.921754e+06</td>\n",
       "      <td>2.459518e+06</td>\n",
       "      <td>33.373152</td>\n",
       "      <td>0.246091</td>\n",
       "      <td>3.542178</td>\n",
       "      <td>0.133548</td>\n",
       "      <td>1.013739e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>4.050000e+04</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-25229.000000</td>\n",
       "      <td>-17912.000000</td>\n",
       "      <td>-24672.000000</td>\n",
       "      <td>-7197.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>3.006000e+03</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.812500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16524.000000</td>\n",
       "      <td>2.385000e+05</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>-19682.000000</td>\n",
       "      <td>-3175.000000</td>\n",
       "      <td>-7479.500000</td>\n",
       "      <td>-4299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193802</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>9.718556e+04</td>\n",
       "      <td>7.524000e+05</td>\n",
       "      <td>0.640621</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.056098</td>\n",
       "      <td>4.725000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471500e+05</td>\n",
       "      <td>5.135310e+05</td>\n",
       "      <td>24903.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-15750.000000</td>\n",
       "      <td>-1648.000000</td>\n",
       "      <td>-4504.000000</td>\n",
       "      <td>-3254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>0.306272</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.004183e+05</td>\n",
       "      <td>1.305000e+06</td>\n",
       "      <td>2.029257</td>\n",
       "      <td>0.116145</td>\n",
       "      <td>0.211615</td>\n",
       "      <td>0.118733</td>\n",
       "      <td>7.500000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>8.086500e+05</td>\n",
       "      <td>34596.000000</td>\n",
       "      <td>6.795000e+05</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-12413.000000</td>\n",
       "      <td>-767.000000</td>\n",
       "      <td>-2010.000000</td>\n",
       "      <td>-1720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198000</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.064043</td>\n",
       "      <td>7.142913e+05</td>\n",
       "      <td>2.254457e+06</td>\n",
       "      <td>4.373481</td>\n",
       "      <td>0.189675</td>\n",
       "      <td>0.395364</td>\n",
       "      <td>0.219167</td>\n",
       "      <td>1.125000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>208.003328</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>6.802079e+08</td>\n",
       "      <td>3.356847e+08</td>\n",
       "      <td>3702.839475</td>\n",
       "      <td>95.097017</td>\n",
       "      <td>264.392053</td>\n",
       "      <td>0.728811</td>\n",
       "      <td>3.900000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  \\\n",
       "count  307507.000000      3.075070e+05  3.075070e+05  307495.000000   \n",
       "mean        0.417047      1.687977e+05  5.990286e+05   27108.666786   \n",
       "std         0.722119      2.371246e+05  4.024926e+05   14493.798379   \n",
       "min         0.000000      2.565000e+04  4.500000e+04    1615.500000   \n",
       "25%         0.000000      1.125000e+05  2.700000e+05   16524.000000   \n",
       "50%         0.000000      1.471500e+05  5.135310e+05   24903.000000   \n",
       "75%         1.000000      2.025000e+05  8.086500e+05   34596.000000   \n",
       "max        19.000000      1.170000e+08  4.050000e+06  258025.500000   \n",
       "\n",
       "       AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE     DAYS_BIRTH  \\\n",
       "count     3.072290e+05               307507.000000  307507.000000   \n",
       "mean      5.383977e+05                    0.020868  -16037.027271   \n",
       "std       3.694472e+05                    0.013831    4363.982424   \n",
       "min       4.050000e+04                    0.000290  -25229.000000   \n",
       "25%       2.385000e+05                    0.010006  -19682.000000   \n",
       "50%       4.500000e+05                    0.018850  -15750.000000   \n",
       "75%       6.795000e+05                    0.028663  -12413.000000   \n",
       "max       4.050000e+06                    0.072508   -7489.000000   \n",
       "\n",
       "       DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  ...  \\\n",
       "count  252133.000000      307507.000000    307507.000000  ...   \n",
       "mean    -2384.142254       -4986.131376     -2994.201670  ...   \n",
       "std      2338.327666        3522.883030      1509.454566  ...   \n",
       "min    -17912.000000      -24672.000000     -7197.000000  ...   \n",
       "25%     -3175.000000       -7479.500000     -4299.000000  ...   \n",
       "50%     -1648.000000       -4504.000000     -3254.000000  ...   \n",
       "75%      -767.000000       -2010.000000     -1720.000000  ...   \n",
       "max         0.000000           0.000000         0.000000  ...   \n",
       "\n",
       "       CURRENT_LOAN_LTV  CURRENT_LOAN_INCOME_CREDIT_PERC  \\\n",
       "count     307229.000000                    307507.000000   \n",
       "mean           1.122994                         0.399669   \n",
       "std            0.124036                         0.507927   \n",
       "min            0.150000                         0.011801   \n",
       "25%            1.000000                         0.193802   \n",
       "50%            1.118800                         0.306272   \n",
       "75%            1.198000                         0.495376   \n",
       "max            6.000000                       208.003328   \n",
       "\n",
       "       CURRENT_LOAN_PAYMENT_RATE  TOTAL_AMT_ANNUITY  TOTAL_AMT_CREDIT  \\\n",
       "count              307495.000000       2.163040e+05      2.163140e+05   \n",
       "mean                    0.053695       9.411559e+05      1.926691e+06   \n",
       "std                     0.022481       5.921754e+06      2.459518e+06   \n",
       "min                     0.022073       3.006000e+03      4.500000e+04   \n",
       "25%                     0.036900       9.718556e+04      7.524000e+05   \n",
       "50%                     0.050000       3.004183e+05      1.305000e+06   \n",
       "75%                     0.064043       7.142913e+05      2.254457e+06   \n",
       "max                     0.124430       6.802079e+08      3.356847e+08   \n",
       "\n",
       "       TOTAL_EFFORT_RATE  TOTAL_INCOME_CREDIT_PERC  TOTAL_PAYMENT_RATE  \\\n",
       "count      216304.000000             216314.000000       216304.000000   \n",
       "mean            5.708165                  0.154313            0.609689   \n",
       "std            33.373152                  0.246091            3.542178   \n",
       "min             0.003830                  0.000603            0.001404   \n",
       "25%             0.640621                  0.072865            0.093214   \n",
       "50%             2.029257                  0.116145            0.211615   \n",
       "75%             4.373481                  0.189675            0.395364   \n",
       "max          3702.839475                 95.097017          264.392053   \n",
       "\n",
       "       DAYS_EMPLOYED_PERC  INCOME_PER_PERSON  \n",
       "count       252133.000000       3.075050e+05  \n",
       "mean             0.156860       9.310608e+04  \n",
       "std              0.133548       1.013739e+05  \n",
       "min             -0.000000       2.812500e+03  \n",
       "25%              0.056098       4.725000e+04  \n",
       "50%              0.118733       7.500000e+04  \n",
       "75%              0.219167       1.125000e+05  \n",
       "max              0.728811       3.900000e+07  \n",
       "\n",
       "[8 rows x 362 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d5d1440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining numerical and categorical columns\n",
    "categorical_cols = [col for col in x.columns if x[col].dtype == 'object']\n",
    "numerical_cols = list(x.drop(categorical_cols, axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4507f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The df contains 8877 infinite values\n"
     ]
    }
   ],
   "source": [
    "# Checking infinite values\n",
    "  \n",
    "count = np.isinf(x[numerical_cols]).values.sum()\n",
    "print(\"The df contains \" + str(count) + \" infinite values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "66d45e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace inf values by NaN\n",
    "x.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec914f7",
   "metadata": {},
   "source": [
    "## II - Split train/test and preprocessing <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "60cf4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5f848ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of preprocessing steps\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('stdscaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3974310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datas\n",
    "x_train_processed = preprocessor.fit_transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19248894",
   "metadata": {},
   "source": [
    "## III - Dimensionality reduction <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f888f4",
   "metadata": {},
   "source": [
    "To speed up our algorithms on our model selection, we will reduce the dimensionality of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "95f76a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions x_train before PCA reduction :  (246005, 670)\n",
      "Dimensions x_test before PCA reduction :  (61502, 670)\n",
      "\n",
      "Proceed PCA on train and test set - done in 21s\n",
      "Dimensions x_train after PCA reduction :  (246005, 289)\n",
      "Dimensions x_test after PCA reduction :  (61502, 289)\n"
     ]
    }
   ],
   "source": [
    "# PCA on processed data\n",
    "\n",
    "print(\"Dimensions x_train before PCA reduction : \", x_train_processed.shape)\n",
    "print(\"Dimensions x_test before PCA reduction : \", x_test_processed.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "\n",
    "print(\"\")\n",
    "with timer(\"Proceed PCA on train and test set\"):\n",
    "    x_train_pca = pca.fit_transform(x_train_processed)\n",
    "    x_test_pca = pca.transform(x_test_processed)\n",
    "\n",
    "print(\"Dimensions x_train after PCA reduction : \", x_train_pca.shape)\n",
    "print(\"Dimensions x_test after PCA reduction : \", x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a90f3",
   "metadata": {},
   "source": [
    "## VI - Creation of folds for cv <a class=\"anchor\" id=\"7-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2e115369",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = create_folds(x_train_pca, y_train, num_folds=num_folds, stratified=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f302d2",
   "metadata": {},
   "source": [
    "# 4. Model testing <a class=\"anchor\" id=\"8-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683b5ff",
   "metadata": {},
   "source": [
    "## I - Dummy classifiers <a class=\"anchor\" id=\"9-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e841d3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_frequent</th>\n",
       "      <th>prior</th>\n",
       "      <th>stratified</th>\n",
       "      <th>uniform</th>\n",
       "      <th>constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.919981</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>0.500376</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079521</td>\n",
       "      <td>0.136565</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499879</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.763748</td>\n",
       "      <td>2.763748</td>\n",
       "      <td>5.070557</td>\n",
       "      <td>17.256768</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.016626</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>0.013446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               most_frequent     prior  stratified    uniform  constant\n",
       "accuracy            0.919981  0.919981    0.853194   0.500376  0.919981\n",
       "f1                  0.000000  0.000000    0.079521   0.136565  0.000000\n",
       "precision           0.000000  0.000000    0.079795   0.079240  0.000000\n",
       "recall              0.000000  0.000000    0.079248   0.493777  0.000000\n",
       "roc_auc             0.500000  0.500000    0.499879   0.500000  0.500000\n",
       "cross_entropy       2.763748  2.763748    5.070557  17.256768  2.763748\n",
       "fit_time            0.016626  0.014415    0.008039   0.012216  0.013446\n",
       "predict_time        0.001482  0.000999    0.001896   0.001412  0.000870"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = test_dummy_classifiers(x_train_pca, y_train, valid_size=0.2, strategies_list=None, random_state=random_state, constant=0)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9fcc7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.499976\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(dummies.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12559819",
   "metadata": {},
   "source": [
    "## II - Quick testing <a class=\"anchor\" id=\"15-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ade35fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick test of some classifiers - done in 366s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.915103</td>\n",
       "      <td>0.920063</td>\n",
       "      <td>0.919981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.045693</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.508850</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.577950</td>\n",
       "      <td>0.771007</td>\n",
       "      <td>0.767978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_entropy</th>\n",
       "      <td>2.932232</td>\n",
       "      <td>2.760942</td>\n",
       "      <td>2.763748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.079616</td>\n",
       "      <td>266.534025</td>\n",
       "      <td>1.469144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time</th>\n",
       "      <td>48.279856</td>\n",
       "      <td>0.060338</td>\n",
       "      <td>0.034857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compute_score_time</th>\n",
       "      <td>0.050733</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>0.133928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    KNeighborsClassifier  LogisticRegression  RidgeClassifier\n",
       "accuracy                        0.915103            0.920063         0.919981\n",
       "f1                              0.045693            0.055249         0.001015\n",
       "precision                       0.227273            0.508850         0.500000\n",
       "recall                          0.025400            0.029210         0.000508\n",
       "roc_auc                         0.577950            0.771007         0.767978\n",
       "cross_entropy                   2.932232            2.760942         2.763748\n",
       "fit_time                        0.079616          266.534025         1.469144\n",
       "predict_time                   48.279856            0.060338         0.034857\n",
       "compute_score_time              0.050733            0.132984         0.133928"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test some models without hyperparameters optimization\n",
    "\n",
    "models_list = [\n",
    "    # 'GradientBoostingClassifier', \n",
    "    # 'RandomForestClassifier', \n",
    "    'KNeighborsClassifier',\n",
    "    # 'GaussianProcessClassifier', \n",
    "    'LogisticRegression', \n",
    "    'RidgeClassifier', \n",
    "    # 'SGDClassifier',\n",
    "    # 'LinearSVC', \n",
    "    # 'NuSVC', \n",
    "    ## 'SVC', \n",
    "    ## 'DecisionTreeClassifier'\n",
    "]\n",
    "\n",
    "with timer(\"Quick test of some classifiers\"):\n",
    "    quick_test_1 = quick_classifiers_test(x_train_pca, y_train, valid_size=0.2,\n",
    "                                          models_list=models_list, random_state=random_state, max_iter=10000, n_jobs=-1)\n",
    "\n",
    "quick_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3e18e4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average roc_auc : 0.705645\n"
     ]
    }
   ],
   "source": [
    "print(\"Average roc_auc : {:.6f}\".format(quick_test_1.iloc[4].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb689f",
   "metadata": {},
   "source": [
    "## III - Linear models <a class=\"anchor\" id=\"10-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9935415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'C': 0.1}\n",
      "Best score on training set : 0.769\n",
      "Proceed LogisticRegression - done in 89s\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LogisticRegression\"):\n",
    "    LogisticRegression_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "64ff2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'alpha': 10}\n",
      "Best score on training set : 0.766\n",
      "Proceed RidgeClassifier - done in 17s\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier\n",
    "\n",
    "model = RidgeClassifier(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'alpha' : np.linspace(1, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed RidgeClassifier\"):\n",
    "    RidgeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea998dd",
   "metadata": {},
   "source": [
    "## IV - KNN <a class=\"anchor\" id=\"11-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "458a7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'n_neighbors': 10}\n",
      "Best score on training set : 0.609\n",
      "Proceed KNeighborsClassifier - done in 704s\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}\n",
    "\n",
    "with timer(\"Proceed KNeighborsClassifier\"):\n",
    "    KNeighborsClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64066bde",
   "metadata": {},
   "source": [
    "## V - SVM <a class=\"anchor\" id=\"12-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c37646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1204, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1043, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.76809311        nan 0.76822499        nan 0.76840678\n",
      "        nan 0.76806893]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters on training set :\n",
      "{'C': 0.7, 'penalty': 'l2'}\n",
      "Best score on training set : 0.768\n",
      "Proceed LinearSVC - done in 11278s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "\n",
    "model = LinearSVC(random_state=random_state, max_iter=10000)\n",
    "param_grid = {'penalty' : ['l1', 'l2'], 'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed LinearSVC\"):\n",
    "    LinearSVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "887aa048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best parameters on training set :\n",
      "{'C': 0.4}\n",
      "Best score on training set : 0.599\n",
      "Proceed SVC - done in 9517s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\anaconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "model = SVC(kernel='rbf', random_state=random_state, max_iter=10000)\n",
    "param_grid = {'C' : np.linspace(0.1, 1, num=4)}\n",
    "\n",
    "with timer(\"Proceed SVC\"):\n",
    "    SVC_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3021e",
   "metadata": {},
   "source": [
    "## VI - Trees and ensemblist methods <a class=\"anchor\" id=\"13-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "359e2e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters on training set :\n",
      "{'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Best score on training set : 0.541\n",
      "Proceed DecisionTreeClassifier - done in 1794s\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=random_state)\n",
    "param_grid = {'min_samples_split' : [2, 4, 8], 'min_samples_leaf' : [1, 3, 5]}\n",
    "\n",
    "with timer(\"Proceed DecisionTreeClassifier\"):\n",
    "    DecisionTreeClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b694f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters on training set :\n",
      "{'n_estimators': 500}\n",
      "Best score on training set : 0.760\n",
      "Proceed GradientBoostingClassifier - done in 43891s\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=random_state)\n",
    "param_grid = {'n_estimators' : [10, 100, 500]}\n",
    "\n",
    "with timer(\"Proceed GradientBoostingClassifier\"):\n",
    "    GradientBoostingClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b62c007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters on training set :\n",
      "{'n_estimators': 500}\n",
      "Best score on training set : 0.670\n",
      "Proceed RandomForestClassifier - done in 12003s\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "param_grid = {'n_estimators' : [10, 100, 500]}\n",
    "\n",
    "with timer(\"Proceed RandomForestClassifier\"):\n",
    "    RandomForestClassifier_clf = run_GridSearchCV(model, x_train_pca, y_train, folds, param_grid, optimized_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b34e30",
   "metadata": {},
   "source": [
    "## VII - Neural networks <a class=\"anchor\" id=\"14-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d054d5",
   "metadata": {},
   "source": [
    "### a. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "069cc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test a standard binary classification NN model (activations hidden = relu, last activation = sigmoid) \n",
    "# and try to optimize hyperparameters (learning rate, nb neurons and layers)\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=0.001, input_shape=[289]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f63207a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "13171374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 828us/step - loss: 0.2864 - auc: 0.6177\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2587 - auc: 0.7181\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2518 - auc: 0.7420\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 815us/step - loss: 0.2485 - auc: 0.7530\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 823us/step - loss: 0.2462 - auc: 0.7598\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2446 - auc: 0.7648\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 820us/step - loss: 0.2433 - auc: 0.7687\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 812us/step - loss: 0.2421 - auc: 0.7720\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 826us/step - loss: 0.2413 - auc: 0.7747\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2404 - auc: 0.7773\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 819us/step - loss: 0.2900 - auc: 0.6014\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 821us/step - loss: 0.2615 - auc: 0.7067\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 867us/step - loss: 0.2528 - auc: 0.7376\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 810us/step - loss: 0.2488 - auc: 0.7511\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 826us/step - loss: 0.2464 - auc: 0.7589\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 823us/step - loss: 0.2447 - auc: 0.7642\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 824us/step - loss: 0.2433 - auc: 0.7686\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 827us/step - loss: 0.2422 - auc: 0.7719\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 825us/step - loss: 0.2412 - auc: 0.7751\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 827us/step - loss: 0.2404 - auc: 0.7775\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 895us/step - loss: 0.2898 - auc: 0.6044\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2612 - auc: 0.7083\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2530 - auc: 0.7376\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2491 - auc: 0.7508\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2467 - auc: 0.7586\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2449 - auc: 0.7642\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 814us/step - loss: 0.2435 - auc: 0.7688\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 801us/step - loss: 0.2424 - auc: 0.7719\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 796us/step - loss: 0.2414 - auc: 0.7751\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2404 - auc: 0.7777\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 800us/step - loss: 0.2877 - auc: 0.6195\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2601 - auc: 0.7116\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 796us/step - loss: 0.2527 - auc: 0.7385\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 786us/step - loss: 0.2489 - auc: 0.7511\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2465 - auc: 0.7583\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2449 - auc: 0.7637\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2435 - auc: 0.7678\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 795us/step - loss: 0.2424 - auc: 0.7713\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2415 - auc: 0.7742\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 802us/step - loss: 0.2406 - auc: 0.7768\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 803us/step - loss: 0.2883 - auc: 0.6059\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 794us/step - loss: 0.2605 - auc: 0.7108\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2520 - auc: 0.7400\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2481 - auc: 0.7532\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 797us/step - loss: 0.2458 - auc: 0.7609\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 793us/step - loss: 0.2442 - auc: 0.7663\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2429 - auc: 0.7703\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2417 - auc: 0.7737\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 811us/step - loss: 0.2408 - auc: 0.7766\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 800us/step - loss: 0.2399 - auc: 0.7793\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 512us/step - loss: 0.4852 - auc: 0.5839\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2986 - auc: 0.6999\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 512us/step - loss: 0.2670 - auc: 0.7371\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2562 - auc: 0.7498\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 508us/step - loss: 0.2512 - auc: 0.7563\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 509us/step - loss: 0.2486 - auc: 0.7597\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 506us/step - loss: 0.2469 - auc: 0.7624\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 509us/step - loss: 0.2459 - auc: 0.7640\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 510us/step - loss: 0.2452 - auc: 0.7653\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2446 - auc: 0.7664\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 4s 504us/step - loss: 0.4851 - auc: 0.5923\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2970 - auc: 0.7067\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2661 - auc: 0.7409\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2556 - auc: 0.7526\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2508 - auc: 0.7580\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2482 - auc: 0.7611\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 509us/step - loss: 0.2467 - auc: 0.7631\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2458 - auc: 0.7646\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2451 - auc: 0.7655\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 522us/step - loss: 0.2447 - auc: 0.7665\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 4s 512us/step - loss: 0.4822 - auc: 0.6033\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2967 - auc: 0.7045\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2660 - auc: 0.7384\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2555 - auc: 0.7511\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2507 - auc: 0.7573\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2482 - auc: 0.7606\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 520us/step - loss: 0.2467 - auc: 0.7625\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 517us/step - loss: 0.2457 - auc: 0.7642\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 518us/step - loss: 0.2451 - auc: 0.7654\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 521us/step - loss: 0.2446 - auc: 0.7663\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 4s 502us/step - loss: 0.4837 - auc: 0.6144\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 504us/step - loss: 0.2974 - auc: 0.7111\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 3s 505us/step - loss: 0.2662 - auc: 0.7433\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 507us/step - loss: 0.2555 - auc: 0.7541\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 506us/step - loss: 0.2507 - auc: 0.7592\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 515us/step - loss: 0.2481 - auc: 0.7623\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 512us/step - loss: 0.2465 - auc: 0.7643\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 512us/step - loss: 0.2456 - auc: 0.7657\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 512us/step - loss: 0.2449 - auc: 0.7665\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2445 - auc: 0.7671\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 4s 508us/step - loss: 0.4920 - auc: 0.5921\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 3s 509us/step - loss: 0.2983 - auc: 0.7026\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 3s 514us/step - loss: 0.2671 - auc: 0.7371\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 3s 506us/step - loss: 0.2564 - auc: 0.7499\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 3s 511us/step - loss: 0.2514 - auc: 0.7559\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 3s 509us/step - loss: 0.2488 - auc: 0.7595\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2473 - auc: 0.7619\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 3s 508us/step - loss: 0.2463 - auc: 0.7632\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 3s 507us/step - loss: 0.2456 - auc: 0.7647\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 3s 513us/step - loss: 0.2452 - auc: 0.7655\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 733us/step - loss: 0.3039 - auc: 0.5771\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 729us/step - loss: 0.2695 - auc: 0.6796\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 729us/step - loss: 0.2599 - auc: 0.7147\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 723us/step - loss: 0.2548 - auc: 0.7315\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 721us/step - loss: 0.2516 - auc: 0.7418\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2495 - auc: 0.7485\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2479 - auc: 0.7537\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 722us/step - loss: 0.2466 - auc: 0.7579\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 721us/step - loss: 0.2455 - auc: 0.7613\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2446 - auc: 0.7640\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 731us/step - loss: 0.2923 - auc: 0.6080\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 729us/step - loss: 0.2683 - auc: 0.6850\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2598 - auc: 0.7149\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2549 - auc: 0.7310\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 732us/step - loss: 0.2516 - auc: 0.7417\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 734us/step - loss: 0.2494 - auc: 0.7488\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 740us/step - loss: 0.2477 - auc: 0.7542\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 744us/step - loss: 0.2464 - auc: 0.7583\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2453 - auc: 0.7616\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 748us/step - loss: 0.2444 - auc: 0.7645\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 740us/step - loss: 0.2955 - auc: 0.6026\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 736us/step - loss: 0.2678 - auc: 0.6891\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2588 - auc: 0.7200\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2538 - auc: 0.7357\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 740us/step - loss: 0.2507 - auc: 0.7455\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2487 - auc: 0.7521\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2470 - auc: 0.7572\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 739us/step - loss: 0.2457 - auc: 0.7609\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 739us/step - loss: 0.2446 - auc: 0.7642\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 750us/step - loss: 0.2437 - auc: 0.7670\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2982 - auc: 0.5832\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2673 - auc: 0.6888\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2585 - auc: 0.7200\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2538 - auc: 0.7356\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 744us/step - loss: 0.2508 - auc: 0.7450\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 754us/step - loss: 0.2488 - auc: 0.7514\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2473 - auc: 0.7561\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 753us/step - loss: 0.2460 - auc: 0.7599\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 806us/step - loss: 0.2450 - auc: 0.7630\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 864us/step - loss: 0.2441 - auc: 0.7657\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.3003 - auc: 0.5757\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2702 - auc: 0.6794\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2603 - auc: 0.7143\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2550 - auc: 0.7317\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2517 - auc: 0.7423\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2495 - auc: 0.7494\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2479 - auc: 0.7544\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2466 - auc: 0.7584\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2455 - auc: 0.7619\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2446 - auc: 0.7646\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 699us/step - loss: 0.2990 - auc: 0.5777\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2705 - auc: 0.6661\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2626 - auc: 0.7007\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2582 - auc: 0.7197\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2552 - auc: 0.7313\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2532 - auc: 0.7390\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2516 - auc: 0.7446\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2503 - auc: 0.7490\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2492 - auc: 0.7526\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2483 - auc: 0.7557\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 703us/step - loss: 0.2894 - auc: 0.6206\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2665 - auc: 0.6897\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2601 - auc: 0.7143\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2564 - auc: 0.7281\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2540 - auc: 0.7371\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2522 - auc: 0.7436\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2508 - auc: 0.7483\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2498 - auc: 0.7521\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2489 - auc: 0.7550\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 715us/step - loss: 0.2482 - auc: 0.7573\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 691us/step - loss: 0.3032 - auc: 0.5640\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2722 - auc: 0.6551\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2636 - auc: 0.6956\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2582 - auc: 0.7187\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2546 - auc: 0.7324\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2521 - auc: 0.7415\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2502 - auc: 0.7479\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2488 - auc: 0.7526\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2476 - auc: 0.7563\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2467 - auc: 0.7589\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 728us/step - loss: 0.2953 - auc: 0.5873\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2686 - auc: 0.6778\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2612 - auc: 0.7089\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2571 - auc: 0.7253\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2544 - auc: 0.7353\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2525 - auc: 0.7424\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2511 - auc: 0.7474\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 712us/step - loss: 0.2500 - auc: 0.7514\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2490 - auc: 0.7544\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2482 - auc: 0.7570\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 716us/step - loss: 0.2995 - auc: 0.5765\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2691 - auc: 0.6748\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 706us/step - loss: 0.2613 - auc: 0.7071\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 717us/step - loss: 0.2568 - auc: 0.7248\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 711us/step - loss: 0.2537 - auc: 0.7362\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2516 - auc: 0.7439\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2500 - auc: 0.7493\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 717us/step - loss: 0.2487 - auc: 0.7536\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2478 - auc: 0.7568\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2469 - auc: 0.7595\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.3046 - auc: 0.5752\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2736 - auc: 0.6635\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2638 - auc: 0.6995\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2580 - auc: 0.7194\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2544 - auc: 0.7317\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 748us/step - loss: 0.2520 - auc: 0.7400\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 744us/step - loss: 0.2501 - auc: 0.7461\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 749us/step - loss: 0.2487 - auc: 0.7508\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 741us/step - loss: 0.2476 - auc: 0.7546\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2466 - auc: 0.7575\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 747us/step - loss: 0.3105 - auc: 0.5651\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2764 - auc: 0.6503\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 731us/step - loss: 0.2666 - auc: 0.6890\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2607 - auc: 0.7106\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2568 - auc: 0.7244\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2539 - auc: 0.7338\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2518 - auc: 0.7411\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2502 - auc: 0.7464\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2489 - auc: 0.7507\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2479 - auc: 0.7545\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 740us/step - loss: 0.3073 - auc: 0.5613\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2768 - auc: 0.6539\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 733us/step - loss: 0.2662 - auc: 0.6928\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2600 - auc: 0.7139\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 734us/step - loss: 0.2561 - auc: 0.7273\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 734us/step - loss: 0.2533 - auc: 0.7364\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2513 - auc: 0.7428\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 741us/step - loss: 0.2497 - auc: 0.7481\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 734us/step - loss: 0.2484 - auc: 0.7522\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2474 - auc: 0.7556\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2944 - auc: 0.5981\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 732us/step - loss: 0.2722 - auc: 0.6738\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 733us/step - loss: 0.2631 - auc: 0.7063\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 723us/step - loss: 0.2579 - auc: 0.7240\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 731us/step - loss: 0.2546 - auc: 0.7350\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 732us/step - loss: 0.2522 - auc: 0.7425\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2503 - auc: 0.7483\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2489 - auc: 0.7527\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 726us/step - loss: 0.2476 - auc: 0.7563\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2466 - auc: 0.7593\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.3076 - auc: 0.5748\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2736 - auc: 0.6641\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2642 - auc: 0.6994\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2588 - auc: 0.7187\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 741us/step - loss: 0.2552 - auc: 0.7306\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2527 - auc: 0.7389\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2509 - auc: 0.7449\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 736us/step - loss: 0.2495 - auc: 0.7493\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 729us/step - loss: 0.2484 - auc: 0.7529\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 730us/step - loss: 0.2474 - auc: 0.7558\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 727us/step - loss: 0.3421 - auc: 0.5308\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 716us/step - loss: 0.2905 - auc: 0.5955\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 715us/step - loss: 0.2806 - auc: 0.6346\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2741 - auc: 0.6606\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 732us/step - loss: 0.2693 - auc: 0.6794\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2656 - auc: 0.6934\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2628 - auc: 0.7043\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2604 - auc: 0.7128\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 722us/step - loss: 0.2585 - auc: 0.7193\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 717us/step - loss: 0.2568 - auc: 0.7253\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 723us/step - loss: 0.3374 - auc: 0.5390\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2898 - auc: 0.6080\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 732us/step - loss: 0.2801 - auc: 0.6431\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 723us/step - loss: 0.2740 - auc: 0.6659\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 739us/step - loss: 0.2695 - auc: 0.6821\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 739us/step - loss: 0.2659 - auc: 0.6942\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 737us/step - loss: 0.2631 - auc: 0.7044\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 735us/step - loss: 0.2607 - auc: 0.7124\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 733us/step - loss: 0.2587 - auc: 0.7189\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 721us/step - loss: 0.2570 - auc: 0.7244\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 720us/step - loss: 0.3548 - auc: 0.5147\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2931 - auc: 0.5745\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2818 - auc: 0.6211\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 724us/step - loss: 0.2744 - auc: 0.6532\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 727us/step - loss: 0.2693 - auc: 0.6746\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 731us/step - loss: 0.2655 - auc: 0.6904\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 726us/step - loss: 0.2626 - auc: 0.7016\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 731us/step - loss: 0.2602 - auc: 0.7101\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 728us/step - loss: 0.2584 - auc: 0.7170\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 720us/step - loss: 0.2569 - auc: 0.7225\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 705us/step - loss: 0.3218 - auc: 0.5436\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2890 - auc: 0.6099\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2793 - auc: 0.6457\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 710us/step - loss: 0.2731 - auc: 0.6691\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2687 - auc: 0.6848\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2653 - auc: 0.6965\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 705us/step - loss: 0.2626 - auc: 0.7058\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 718us/step - loss: 0.2604 - auc: 0.7133\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 722us/step - loss: 0.2586 - auc: 0.7196\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 715us/step - loss: 0.2570 - auc: 0.7252\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 717us/step - loss: 0.3197 - auc: 0.5263\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 725us/step - loss: 0.2900 - auc: 0.5953\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2804 - auc: 0.6337\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 709us/step - loss: 0.2742 - auc: 0.6589\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 711us/step - loss: 0.2697 - auc: 0.6771\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2662 - auc: 0.6904\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 711us/step - loss: 0.2634 - auc: 0.7008\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2612 - auc: 0.7096\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 713us/step - loss: 0.2593 - auc: 0.7165\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 717us/step - loss: 0.2577 - auc: 0.7222\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 770us/step - loss: 0.2591 - auc: 0.7192\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 762us/step - loss: 0.2443 - auc: 0.7664\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2407 - auc: 0.7771\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2383 - auc: 0.7837\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 798us/step - loss: 0.2364 - auc: 0.7894\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 809us/step - loss: 0.2346 - auc: 0.7939\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2330 - auc: 0.7981\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2312 - auc: 0.8034\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2299 - auc: 0.8066\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2280 - auc: 0.8115\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 763us/step - loss: 0.2580 - auc: 0.7255\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2441 - auc: 0.7673\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2408 - auc: 0.7773\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 761us/step - loss: 0.2385 - auc: 0.7837\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2369 - auc: 0.7887\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2350 - auc: 0.7937\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2331 - auc: 0.7987\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2315 - auc: 0.8028\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2298 - auc: 0.8074\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2282 - auc: 0.8115\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 7s 783us/step - loss: 0.2581 - auc: 0.7232\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2443 - auc: 0.7660\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2408 - auc: 0.7767\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2387 - auc: 0.7828\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 793us/step - loss: 0.2367 - auc: 0.7887\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2351 - auc: 0.7932\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2335 - auc: 0.7973\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 804us/step - loss: 0.2317 - auc: 0.8018\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 789us/step - loss: 0.2303 - auc: 0.8054\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 782us/step - loss: 0.2287 - auc: 0.8099\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 784us/step - loss: 0.2567 - auc: 0.7275\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2444 - auc: 0.7666\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2412 - auc: 0.7758\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2388 - auc: 0.7825\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2367 - auc: 0.7883\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2350 - auc: 0.7927\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2337 - auc: 0.7966\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2319 - auc: 0.8008\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2302 - auc: 0.8054\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2286 - auc: 0.8091\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 783us/step - loss: 0.2587 - auc: 0.7209\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2449 - auc: 0.7652\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2412 - auc: 0.7761\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2390 - auc: 0.7822\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 788us/step - loss: 0.2373 - auc: 0.7877\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2354 - auc: 0.7926\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 792us/step - loss: 0.2336 - auc: 0.7975\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2320 - auc: 0.8011\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 790us/step - loss: 0.2304 - auc: 0.8052\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 791us/step - loss: 0.2288 - auc: 0.8092\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 737us/step - loss: 0.3059 - auc: 0.5623\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 736us/step - loss: 0.2751 - auc: 0.6547\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2655 - auc: 0.6928\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 740us/step - loss: 0.2599 - auc: 0.7132\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 736us/step - loss: 0.2561 - auc: 0.7264\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 748us/step - loss: 0.2535 - auc: 0.7355\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2516 - auc: 0.7417\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 740us/step - loss: 0.2501 - auc: 0.7468\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2489 - auc: 0.7506\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 753us/step - loss: 0.2479 - auc: 0.7539\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 744us/step - loss: 0.3045 - auc: 0.5669\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2757 - auc: 0.6577\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2661 - auc: 0.6940\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2605 - auc: 0.7139\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2568 - auc: 0.7268\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 745us/step - loss: 0.2541 - auc: 0.7354\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2521 - auc: 0.7421\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 753us/step - loss: 0.2505 - auc: 0.7468\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2493 - auc: 0.7507\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2483 - auc: 0.7541\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 748us/step - loss: 0.3085 - auc: 0.5619\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 736us/step - loss: 0.2772 - auc: 0.6499\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 740us/step - loss: 0.2674 - auc: 0.6887\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2613 - auc: 0.7107\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2573 - auc: 0.7244\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 739us/step - loss: 0.2545 - auc: 0.7334\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 743us/step - loss: 0.2524 - auc: 0.7404\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2507 - auc: 0.7461\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 738us/step - loss: 0.2493 - auc: 0.7502\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2482 - auc: 0.7537\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.3084 - auc: 0.5603\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2771 - auc: 0.6471\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 749us/step - loss: 0.2675 - auc: 0.6855\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 747us/step - loss: 0.2616 - auc: 0.7072\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 753us/step - loss: 0.2577 - auc: 0.7214\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2548 - auc: 0.7311\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2526 - auc: 0.7382\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 753us/step - loss: 0.2510 - auc: 0.7435\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 751us/step - loss: 0.2496 - auc: 0.7477\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 760us/step - loss: 0.2484 - auc: 0.7514\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 743us/step - loss: 0.3057 - auc: 0.5751\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 749us/step - loss: 0.2753 - auc: 0.6581\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 748us/step - loss: 0.2663 - auc: 0.6914\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2607 - auc: 0.7118\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 746us/step - loss: 0.2568 - auc: 0.7252\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 752us/step - loss: 0.2540 - auc: 0.7348\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 743us/step - loss: 0.2519 - auc: 0.7416\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 743us/step - loss: 0.2503 - auc: 0.7470\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 742us/step - loss: 0.2490 - auc: 0.7507\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 763us/step - loss: 0.2480 - auc: 0.7541\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 701us/step - loss: 0.2937 - auc: 0.6092\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2603 - auc: 0.7105\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2540 - auc: 0.7351\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2508 - auc: 0.7462\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2488 - auc: 0.7530\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 707us/step - loss: 0.2473 - auc: 0.7576\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2462 - auc: 0.7611\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2453 - auc: 0.7638\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2445 - auc: 0.7663\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 708us/step - loss: 0.2439 - auc: 0.7683\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 697us/step - loss: 0.2924 - auc: 0.6225\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2604 - auc: 0.7109\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 703us/step - loss: 0.2540 - auc: 0.7355\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2508 - auc: 0.7471\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2488 - auc: 0.7534\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2473 - auc: 0.7583\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2461 - auc: 0.7617\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2451 - auc: 0.7644\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 699us/step - loss: 0.2443 - auc: 0.7668\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 702us/step - loss: 0.2436 - auc: 0.7687\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 693us/step - loss: 0.2892 - auc: 0.6330\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 692us/step - loss: 0.2601 - auc: 0.7119\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2543 - auc: 0.7345\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 704us/step - loss: 0.2511 - auc: 0.7455\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2490 - auc: 0.7523\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2476 - auc: 0.7565\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 698us/step - loss: 0.2465 - auc: 0.7599\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2456 - auc: 0.7627\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2449 - auc: 0.7648\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2442 - auc: 0.7666\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 706us/step - loss: 0.2873 - auc: 0.6219\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 693us/step - loss: 0.2590 - auc: 0.7172\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 690us/step - loss: 0.2533 - auc: 0.7383\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2502 - auc: 0.7486\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 690us/step - loss: 0.2481 - auc: 0.7552\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 687us/step - loss: 0.2466 - auc: 0.7598\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 687us/step - loss: 0.2455 - auc: 0.7633\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2446 - auc: 0.7660\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2438 - auc: 0.7682\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2432 - auc: 0.7700\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 5s 705us/step - loss: 0.2858 - auc: 0.6352\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2604 - auc: 0.7117\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 4s 697us/step - loss: 0.2542 - auc: 0.7347\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 4s 695us/step - loss: 0.2508 - auc: 0.7463\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 4s 701us/step - loss: 0.2487 - auc: 0.7530\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 4s 694us/step - loss: 0.2472 - auc: 0.7579\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 4s 693us/step - loss: 0.2461 - auc: 0.7612\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 4s 696us/step - loss: 0.2452 - auc: 0.7638\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 4s 700us/step - loss: 0.2445 - auc: 0.7662\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 4s 692us/step - loss: 0.2439 - auc: 0.7681\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 771us/step - loss: 0.3092 - auc: 0.5633\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2802 - auc: 0.6355\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2711 - auc: 0.6720\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2652 - auc: 0.6949\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2611 - auc: 0.7104\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2580 - auc: 0.7213\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2555 - auc: 0.7298\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 772us/step - loss: 0.2536 - auc: 0.7363\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 774us/step - loss: 0.2520 - auc: 0.7413\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 770us/step - loss: 0.2506 - auc: 0.7455\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 768us/step - loss: 0.3066 - auc: 0.5761\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2750 - auc: 0.6568\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 766us/step - loss: 0.2660 - auc: 0.6927\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 765us/step - loss: 0.2607 - auc: 0.7122\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 773us/step - loss: 0.2571 - auc: 0.7247\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2545 - auc: 0.7333\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2526 - auc: 0.7397\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 778us/step - loss: 0.2510 - auc: 0.7448\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 771us/step - loss: 0.2498 - auc: 0.7485\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2487 - auc: 0.7520\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 788us/step - loss: 0.3085 - auc: 0.5510\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2801 - auc: 0.6302\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 776us/step - loss: 0.2701 - auc: 0.6741\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 784us/step - loss: 0.2639 - auc: 0.6990\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2597 - auc: 0.7149\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2567 - auc: 0.7257\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2543 - auc: 0.7337\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2525 - auc: 0.7398\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 780us/step - loss: 0.2511 - auc: 0.7443\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2498 - auc: 0.7483\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 781us/step - loss: 0.3193 - auc: 0.5358\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 775us/step - loss: 0.2828 - auc: 0.6115\n",
      "Epoch 3/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2741 - auc: 0.6518\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 781us/step - loss: 0.2681 - auc: 0.6787\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 777us/step - loss: 0.2635 - auc: 0.6976\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 779us/step - loss: 0.2600 - auc: 0.7117\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 787us/step - loss: 0.2572 - auc: 0.7226\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 783us/step - loss: 0.2550 - auc: 0.7310\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 785us/step - loss: 0.2532 - auc: 0.7374\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 817us/step - loss: 0.2517 - auc: 0.7424\n",
      "Epoch 1/10\n",
      "6151/6151 [==============================] - 6s 787us/step - loss: 0.3088 - auc: 0.5654\n",
      "Epoch 2/10\n",
      "6151/6151 [==============================] - 5s 758us/step - loss: 0.2805 - auc: 0.6385\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6151/6151 [==============================] - 5s 769us/step - loss: 0.2706 - auc: 0.6754\n",
      "Epoch 4/10\n",
      "6151/6151 [==============================] - 5s 757us/step - loss: 0.2642 - auc: 0.6986\n",
      "Epoch 5/10\n",
      "6151/6151 [==============================] - 5s 755us/step - loss: 0.2596 - auc: 0.7144\n",
      "Epoch 6/10\n",
      "6151/6151 [==============================] - 5s 759us/step - loss: 0.2564 - auc: 0.7257\n",
      "Epoch 7/10\n",
      "6151/6151 [==============================] - 5s 764us/step - loss: 0.2540 - auc: 0.7337\n",
      "Epoch 8/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2522 - auc: 0.7398\n",
      "Epoch 9/10\n",
      "6151/6151 [==============================] - 5s 756us/step - loss: 0.2508 - auc: 0.7446\n",
      "Epoch 10/10\n",
      "6151/6151 [==============================] - 5s 768us/step - loss: 0.2496 - auc: 0.7485\n",
      "Epoch 1/10\n",
      "7688/7688 [==============================] - 5s 507us/step - loss: 0.4517 - auc: 0.5954\n",
      "Epoch 2/10\n",
      "7688/7688 [==============================] - 4s 505us/step - loss: 0.2823 - auc: 0.7173\n",
      "Epoch 3/10\n",
      "7688/7688 [==============================] - 4s 500us/step - loss: 0.2590 - auc: 0.7456\n",
      "Epoch 4/10\n",
      "7688/7688 [==============================] - 4s 506us/step - loss: 0.2516 - auc: 0.7555\n",
      "Epoch 5/10\n",
      "7688/7688 [==============================] - 4s 510us/step - loss: 0.2483 - auc: 0.7601\n",
      "Epoch 6/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2466 - auc: 0.7624\n",
      "Epoch 7/10\n",
      "7688/7688 [==============================] - 4s 506us/step - loss: 0.2456 - auc: 0.7644\n",
      "Epoch 8/10\n",
      "7688/7688 [==============================] - 4s 509us/step - loss: 0.2449 - auc: 0.7657\n",
      "Epoch 9/10\n",
      "7688/7688 [==============================] - 4s 508us/step - loss: 0.2445 - auc: 0.7666\n",
      "Epoch 10/10\n",
      "7688/7688 [==============================] - 4s 507us/step - loss: 0.2442 - auc: 0.7673\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=[(array([     0,      1,      2, ..., 246002, 246003, 246004]),\n",
       "                        array([     8,     13,     18, ..., 245984, 245985, 245992])),\n",
       "                       (array([     0,      1,      4, ..., 246002, 246003, 246004]),\n",
       "                        array([     2,      3,      5, ..., 245991, 245997, 245999])),\n",
       "                       (array([     0,      2,      3, ..., 246000, 246001, 246003]),\n",
       "                        array([     1,      6,     15, ..., 245998, 246002, 246004])),\n",
       "                       (array([     0,      1,      2, ..., 245999, 246002, 246004]),\n",
       "                        array([     7,      9,     16, ..., 246000, 246001, 24600...\n",
       "        41.40816327,  43.42857143,  45.44897959,  47.46938776,\n",
       "        49.48979592,  51.51020408,  53.53061224,  55.55102041,\n",
       "        57.57142857,  59.59183673,  61.6122449 ,  63.63265306,\n",
       "        65.65306122,  67.67346939,  69.69387755,  71.71428571,\n",
       "        73.73469388,  75.75510204,  77.7755102 ,  79.79591837,\n",
       "        81.81632653,  83.83673469,  85.85714286,  87.87755102,\n",
       "        89.89795918,  91.91836735,  93.93877551,  95.95918367,\n",
       "        97.97959184, 100.        ])},\n",
       "                   random_state=50, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=[(array([     0,      1,      2, ..., 246002, 246003, 246004]),\n",
       "                        array([     8,     13,     18, ..., 245984, 245985, 245992])),\n",
       "                       (array([     0,      1,      4, ..., 246002, 246003, 246004]),\n",
       "                        array([     2,      3,      5, ..., 245991, 245997, 245999])),\n",
       "                       (array([     0,      2,      3, ..., 246000, 246001, 246003]),\n",
       "                        array([     1,      6,     15, ..., 245998, 246002, 246004])),\n",
       "                       (array([     0,      1,      2, ..., 245999, 246002, 246004]),\n",
       "                        array([     7,      9,     16, ..., 246000, 246001, 24600...\n",
       "        41.40816327,  43.42857143,  45.44897959,  47.46938776,\n",
       "        49.48979592,  51.51020408,  53.53061224,  55.55102041,\n",
       "        57.57142857,  59.59183673,  61.6122449 ,  63.63265306,\n",
       "        65.65306122,  67.67346939,  69.69387755,  71.71428571,\n",
       "        73.73469388,  75.75510204,  77.7755102 ,  79.79591837,\n",
       "        81.81632653,  83.83673469,  85.85714286,  87.87755102,\n",
       "        89.89795918,  91.91836735,  93.93877551,  95.95918367,\n",
       "        97.97959184, 100.        ])},\n",
       "                   random_state=50, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000002177683C1F0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000002177683C1F0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=[(array([     0,      1,      2, ..., 246002, 246003, 246004]),\n",
       "                        array([     8,     13,     18, ..., 245984, 245985, 245992])),\n",
       "                       (array([     0,      1,      4, ..., 246002, 246003, 246004]),\n",
       "                        array([     2,      3,      5, ..., 245991, 245997, 245999])),\n",
       "                       (array([     0,      2,      3, ..., 246000, 246001, 246003]),\n",
       "                        array([     1,      6,     15, ..., 245998, 246002, 246004])),\n",
       "                       (array([     0,      1,      2, ..., 245999, 246002, 246004]),\n",
       "                        array([     7,      9,     16, ..., 246000, 246001, 24600...\n",
       "        41.40816327,  43.42857143,  45.44897959,  47.46938776,\n",
       "        49.48979592,  51.51020408,  53.53061224,  55.55102041,\n",
       "        57.57142857,  59.59183673,  61.6122449 ,  63.63265306,\n",
       "        65.65306122,  67.67346939,  69.69387755,  71.71428571,\n",
       "        73.73469388,  75.75510204,  77.7755102 ,  79.79591837,\n",
       "        81.81632653,  83.83673469,  85.85714286,  87.87755102,\n",
       "        89.89795918,  91.91836735,  93.93877551,  95.95918367,\n",
       "        97.97959184, 100.        ])},\n",
       "                   random_state=50, scoring='roc_auc')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing hyperparameters\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.linspace(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "} \n",
    "\n",
    "nn_clf = RandomizedSearchCV(keras_clf, param_distribs, n_iter=10, \n",
    "                            cv=folds, scoring=optimized_metric, random_state=random_state)\n",
    "\n",
    "nn_clf.fit(x_train_pca, y_train, epochs=10, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "132094c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters on training set :\n",
      "{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}\n",
      "Best score on training set : 0.764\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters on training set :\")\n",
    "print(nn_clf.best_params_)\n",
    "print(\"Best score on training set : {:.3f}\".format(nn_clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c0205",
   "metadata": {},
   "source": [
    "### b. Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ac6d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4165bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data=x_train_pca , columns=[\"input_{}\".format(i+1) for i in range(x_train_pca.shape[1])])\n",
    "test_df['labels'] = ['default' if i==1 else 'regular' for i in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49791c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter(seed=random_state)(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d831793",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularPandas(\n",
    "    test_df,\n",
    "    splits = splits,\n",
    "    cont_names=[\"input_{}\".format(i+1) for i in range(x_train_pca.shape[1])],\n",
    "    y_names=\"labels\", y_block = CategoryBlock(),\n",
    ").dataloaders(path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "73234aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_auc = RocAucBinary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b36bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 2 layers of 10 neurons, with ReLU first the first and sigmoid the 2nd\n",
    "\n",
    "learn = tabular_learner(dls, metrics=score_auc, layers=[10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ef36b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(slide=0.04786301031708717, valley=0.10000000149011612)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=(slide, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ec866d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.237841</td>\n",
       "      <td>0.255403</td>\n",
       "      <td>0.760415</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.262362</td>\n",
       "      <td>0.258417</td>\n",
       "      <td>0.753688</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>0.270894</td>\n",
       "      <td>0.757241</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261931</td>\n",
       "      <td>0.260178</td>\n",
       "      <td>0.759460</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262786</td>\n",
       "      <td>0.258288</td>\n",
       "      <td>0.755321</td>\n",
       "      <td>00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.263962</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.752103</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.252236</td>\n",
       "      <td>0.259148</td>\n",
       "      <td>0.756578</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.241641</td>\n",
       "      <td>0.251884</td>\n",
       "      <td>0.754251</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.305918</td>\n",
       "      <td>0.752334</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.233336</td>\n",
       "      <td>0.273764</td>\n",
       "      <td>0.756036</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.262046</td>\n",
       "      <td>0.255855</td>\n",
       "      <td>0.759490</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.252313</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.759052</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.245776</td>\n",
       "      <td>0.248234</td>\n",
       "      <td>0.760576</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.251802</td>\n",
       "      <td>0.247650</td>\n",
       "      <td>0.761951</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.238385</td>\n",
       "      <td>0.278128</td>\n",
       "      <td>0.755785</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.249564</td>\n",
       "      <td>0.248548</td>\n",
       "      <td>0.757657</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.243158</td>\n",
       "      <td>0.256202</td>\n",
       "      <td>0.757556</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.246693</td>\n",
       "      <td>0.268470</td>\n",
       "      <td>0.758446</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.254911</td>\n",
       "      <td>0.252147</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.253003</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>0.756309</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(20, lr=0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9008f6",
   "metadata": {},
   "source": [
    "The model doesn't seem to improve over time, let's increase the complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0bc5a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network with 4 layers of 1000 neurons, with ReLU for hidden layers and sigmoid the final layer\n",
    "\n",
    "learn_2 = tabular_learner(dls, metrics=score_auc, layers=[1000,1000,1000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "af43865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(slide=0.019054606556892395, valley=6.30957365501672e-05)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_2.lr_find(suggest_funcs=(slide, valley))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8dfa8a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.251316</td>\n",
       "      <td>0.253050</td>\n",
       "      <td>0.763220</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.244244</td>\n",
       "      <td>0.767249</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.229934</td>\n",
       "      <td>0.254283</td>\n",
       "      <td>0.768114</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227457</td>\n",
       "      <td>0.249193</td>\n",
       "      <td>0.756246</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.236180</td>\n",
       "      <td>0.252936</td>\n",
       "      <td>0.737640</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.223913</td>\n",
       "      <td>0.276008</td>\n",
       "      <td>0.730849</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.204805</td>\n",
       "      <td>0.290079</td>\n",
       "      <td>0.720266</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.219292</td>\n",
       "      <td>0.315334</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.199774</td>\n",
       "      <td>0.452669</td>\n",
       "      <td>0.716147</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.177207</td>\n",
       "      <td>1.059385</td>\n",
       "      <td>0.705969</td>\n",
       "      <td>03:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_2.fit(10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5426c32",
   "metadata": {},
   "source": [
    "We seem to improve our loss for our training set but not the validation so we are probably overfitting the datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636224ce",
   "metadata": {},
   "source": [
    "## VIII - Compare <a class=\"anchor\" id=\"16-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7647345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scores in this iteration\n",
    "\n",
    "cv_clfs = {\n",
    "    'LogisticRegression' : LogisticRegression_clf,\n",
    "    'RidgeClassifier' : RidgeClassifier_clf,\n",
    "    'KNeighborsClassifier' : KNeighborsClassifier_clf,\n",
    "    'LinearSVC' : LinearSVC_clf,\n",
    "    'SVC' : SVC_clf,\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier_clf,\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier_clf,\n",
    "    'RandomForestClassifier' : RandomForestClassifier_clf,\n",
    "    'NeuralNetwork' : nn_clf,\n",
    "}\n",
    "\n",
    "iteration_1 = pd.DataFrame()\n",
    "\n",
    "for key, clf in cv_clfs.items():\n",
    "    iteration_1[key] = [clf.best_score_, clf.best_params_]\n",
    "    \n",
    "iteration_1.index = ['best_score_ : ' + optimized_metric, 'best_params_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "810c4c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>SVC</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_score_ : roc_auc</th>\n",
       "      <td>0.768526</td>\n",
       "      <td>0.766282</td>\n",
       "      <td>0.609496</td>\n",
       "      <td>0.768407</td>\n",
       "      <td>0.598855</td>\n",
       "      <td>0.540549</td>\n",
       "      <td>0.76431</td>\n",
       "      <td>0.760152</td>\n",
       "      <td>0.670222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_params_</th>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>{'C': 0.7, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.4}</td>\n",
       "      <td>{'min_samples_leaf': 5, 'min_samples_split': 2}</td>\n",
       "      <td>{'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LogisticRegression RidgeClassifier KNeighborsClassifier  \\\n",
       "best_score_ : roc_auc           0.768526        0.766282             0.609496   \n",
       "best_params_                  {'C': 0.1}   {'alpha': 10}  {'n_neighbors': 10}   \n",
       "\n",
       "                                         LinearSVC         SVC  \\\n",
       "best_score_ : roc_auc                     0.768407    0.598855   \n",
       "best_params_           {'C': 0.7, 'penalty': 'l2'}  {'C': 0.4}   \n",
       "\n",
       "                                                DecisionTreeClassifier  \\\n",
       "best_score_ : roc_auc                                         0.540549   \n",
       "best_params_           {'min_samples_leaf': 5, 'min_samples_split': 2}   \n",
       "\n",
       "                                                                                                  NeuralNetwork  \\\n",
       "best_score_ : roc_auc                                                                                   0.76431   \n",
       "best_params_           {'learning_rate': 0.0009729020135732503, 'n_hidden': 0, 'n_neurons': 13.122448979591836}   \n",
       "\n",
       "                      GradientBoostingClassifier RandomForestClassifier  \n",
       "best_score_ : roc_auc                   0.760152               0.670222  \n",
       "best_params_               {'n_estimators': 500}  {'n_estimators': 500}  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "19b555d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression            0.768526\n",
       "LinearSVC                     0.768407\n",
       "RidgeClassifier               0.766282\n",
       "NeuralNetwork                  0.76431\n",
       "GradientBoostingClassifier    0.760152\n",
       "RandomForestClassifier        0.670222\n",
       "KNeighborsClassifier          0.609496\n",
       "SVC                           0.598855\n",
       "DecisionTreeClassifier        0.540549\n",
       "Name: best_score_ : roc_auc, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_1.iloc[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2a21dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_1.to_csv('./Scores/iteration_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be7513",
   "metadata": {},
   "source": [
    "Valeurs testées première itération (cleaned_data_1):\n",
    "- LogisticRegression : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.1 -> tester plus petit\n",
    "- RidgeClassifier : {'alpha' : np.linspace(1, 10, num=4, dtype=int)}, best : alpha = 10 -> tester plus grand\n",
    "- KNeighborsClassifier : {'n_neighbors' : np.linspace(3, 10, num=4, dtype=int)}, best : n_neighbors = 10 > tester plus grand\n",
    "- LinearSVC : {'penalty' : ['l1', 'l2'], 'C' : np.linspace(0.1, 1, num=4)}, bests :\n",
    "    - C = 0.7 --> tester valeurs autour\n",
    "    - penalty = l2 --> conserver\n",
    "- SVC : {'C' : np.linspace(0.1, 1, num=4)}, best : C = 0.4 -> tester valeurs autour\n",
    "- DecisionTreeClassifier : {'min_samples_split' : [2, 4, 8], 'min_samples_leaf' : [1, 3, 5]}, bests :\n",
    "    - min_samples_split = 2 --> conserver\n",
    "    - min_samples_leaf = 5 --> tester plus grand\n",
    "- GradientBoostingClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand\n",
    "- RandomForestClassifier : {'n_estimators' : [10, 100, 500]}, best : n_estimators = 500 -> tester plus grand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
